{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2n_3Hsjrk7Dr"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! wget https://raw.githubusercontent.com/TemaBlag/Yandex_Training/main/ml_training_3/hw5/train.csv\n",
        "# ! wget https://raw.githubusercontent.com/TemaBlag/Yandex_Training/main/ml_training_3/hw5/test.csv"
      ],
      "metadata": {
        "id": "1dTzcaVDq224"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train = pd.read_csv('train.csv')\n",
        "df_test = pd.read_csv('test.csv')"
      ],
      "metadata": {
        "id": "d5kwW-mpq25d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iltY2ohSq28U",
        "outputId": "332e57db-5d58-414c-a414-f3e682861936"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1288, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "dQgzeU4ptdFP",
        "outputId": "a45b60b8-5a94-40e6-e4d5-3e84eb13dbcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "    area  perimeter  major_axis  minor_axis  eccentricity   eqdiasq  solidity  \\\n",
              "0  75516  1731.4840    411.7352    245.7620        0.8023  310.0806    0.9148   \n",
              "1  98903  1374.4370    477.2451    269.7676        0.8249  354.8622    0.9585   \n",
              "2  84746  1311.1570    482.7735    235.9040        0.8725  328.4843    0.9121   \n",
              "3  98184  1463.1680    434.3769    292.6472        0.7390  353.5700    0.9543   \n",
              "4  94170  1267.7271    440.1109    278.4162        0.7745  346.2672    0.9643   \n",
              "\n",
              "   convex_area  extent  aspect_ratio  roundness  compactness  shapefactor_1  \\\n",
              "0        82546  0.7169        1.6753     0.3165       0.7531         0.0055   \n",
              "1       103181  0.7679        1.7691     0.6579       0.7436         0.0048   \n",
              "2        92914  0.7162        2.0465     0.6195       0.6804         0.0057   \n",
              "3       102890  0.7316        1.4843     0.5763       0.8140         0.0044   \n",
              "4        97656  0.6836        1.5808     0.7363       0.7868         0.0047   \n",
              "\n",
              "   shapefactor_2  shapefactor_3  shapefactor_4  target  \n",
              "0         0.0033         0.5672         0.9502       1  \n",
              "1         0.0027         0.5529         0.9781       0  \n",
              "2         0.0028         0.4630         0.9474       1  \n",
              "3         0.0030         0.6625         0.9834       0  \n",
              "4         0.0030         0.6190         0.9785       0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4fe88bc0-4394-47de-82fc-0210c3e283f1\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>area</th>\n",
              "      <th>perimeter</th>\n",
              "      <th>major_axis</th>\n",
              "      <th>minor_axis</th>\n",
              "      <th>eccentricity</th>\n",
              "      <th>eqdiasq</th>\n",
              "      <th>solidity</th>\n",
              "      <th>convex_area</th>\n",
              "      <th>extent</th>\n",
              "      <th>aspect_ratio</th>\n",
              "      <th>roundness</th>\n",
              "      <th>compactness</th>\n",
              "      <th>shapefactor_1</th>\n",
              "      <th>shapefactor_2</th>\n",
              "      <th>shapefactor_3</th>\n",
              "      <th>shapefactor_4</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>75516</td>\n",
              "      <td>1731.4840</td>\n",
              "      <td>411.7352</td>\n",
              "      <td>245.7620</td>\n",
              "      <td>0.8023</td>\n",
              "      <td>310.0806</td>\n",
              "      <td>0.9148</td>\n",
              "      <td>82546</td>\n",
              "      <td>0.7169</td>\n",
              "      <td>1.6753</td>\n",
              "      <td>0.3165</td>\n",
              "      <td>0.7531</td>\n",
              "      <td>0.0055</td>\n",
              "      <td>0.0033</td>\n",
              "      <td>0.5672</td>\n",
              "      <td>0.9502</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>98903</td>\n",
              "      <td>1374.4370</td>\n",
              "      <td>477.2451</td>\n",
              "      <td>269.7676</td>\n",
              "      <td>0.8249</td>\n",
              "      <td>354.8622</td>\n",
              "      <td>0.9585</td>\n",
              "      <td>103181</td>\n",
              "      <td>0.7679</td>\n",
              "      <td>1.7691</td>\n",
              "      <td>0.6579</td>\n",
              "      <td>0.7436</td>\n",
              "      <td>0.0048</td>\n",
              "      <td>0.0027</td>\n",
              "      <td>0.5529</td>\n",
              "      <td>0.9781</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>84746</td>\n",
              "      <td>1311.1570</td>\n",
              "      <td>482.7735</td>\n",
              "      <td>235.9040</td>\n",
              "      <td>0.8725</td>\n",
              "      <td>328.4843</td>\n",
              "      <td>0.9121</td>\n",
              "      <td>92914</td>\n",
              "      <td>0.7162</td>\n",
              "      <td>2.0465</td>\n",
              "      <td>0.6195</td>\n",
              "      <td>0.6804</td>\n",
              "      <td>0.0057</td>\n",
              "      <td>0.0028</td>\n",
              "      <td>0.4630</td>\n",
              "      <td>0.9474</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>98184</td>\n",
              "      <td>1463.1680</td>\n",
              "      <td>434.3769</td>\n",
              "      <td>292.6472</td>\n",
              "      <td>0.7390</td>\n",
              "      <td>353.5700</td>\n",
              "      <td>0.9543</td>\n",
              "      <td>102890</td>\n",
              "      <td>0.7316</td>\n",
              "      <td>1.4843</td>\n",
              "      <td>0.5763</td>\n",
              "      <td>0.8140</td>\n",
              "      <td>0.0044</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.6625</td>\n",
              "      <td>0.9834</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>94170</td>\n",
              "      <td>1267.7271</td>\n",
              "      <td>440.1109</td>\n",
              "      <td>278.4162</td>\n",
              "      <td>0.7745</td>\n",
              "      <td>346.2672</td>\n",
              "      <td>0.9643</td>\n",
              "      <td>97656</td>\n",
              "      <td>0.6836</td>\n",
              "      <td>1.5808</td>\n",
              "      <td>0.7363</td>\n",
              "      <td>0.7868</td>\n",
              "      <td>0.0047</td>\n",
              "      <td>0.0030</td>\n",
              "      <td>0.6190</td>\n",
              "      <td>0.9785</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4fe88bc0-4394-47de-82fc-0210c3e283f1')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4fe88bc0-4394-47de-82fc-0210c3e283f1 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4fe88bc0-4394-47de-82fc-0210c3e283f1');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-90d748eb-a1b4-4da4-be89-307b2d60be7c\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-90d748eb-a1b4-4da4-be89-307b2d60be7c')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-90d748eb-a1b4-4da4-be89-307b2d60be7c button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "df_train",
              "summary": "{\n  \"name\": \"df_train\",\n  \"rows\": 1288,\n  \"fields\": [\n    {\n      \"column\": \"area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 12890,\n        \"min\": 37130,\n        \"max\": 124008,\n        \"num_unique_values\": 1273,\n        \"samples\": [\n          57245,\n          93391,\n          74823\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"perimeter\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 374.37914047626884,\n        \"min\": 858.363,\n        \"max\": 2755.0491,\n        \"num_unique_values\": 1288,\n        \"samples\": [\n          1382.0341,\n          1240.946,\n          1524.917\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"major_axis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 32.06831775651199,\n        \"min\": 321.4255,\n        \"max\": 535.6422,\n        \"num_unique_values\": 1287,\n        \"samples\": [\n          413.738,\n          460.3441,\n          370.5511\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"minor_axis\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 30.088274722576802,\n        \"min\": 135.6949,\n        \"max\": 383.0461,\n        \"num_unique_values\": 1288,\n        \"samples\": [\n          233.7686,\n          238.3388,\n          246.1724\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eccentricity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04908663782140076,\n        \"min\": 0.5049,\n        \"max\": 0.9454,\n        \"num_unique_values\": 869,\n        \"samples\": [\n          0.873,\n          0.8592,\n          0.8141\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"eqdiasq\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 26.202101668840385,\n        \"min\": 217.429,\n        \"max\": 397.3561,\n        \"num_unique_values\": 1273,\n        \"samples\": [\n          269.9752,\n          344.832,\n          308.6545\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"solidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.048664959741037336,\n        \"min\": 0.6802,\n        \"max\": 0.9948,\n        \"num_unique_values\": 792,\n        \"samples\": [\n          0.9849,\n          0.9114,\n          0.8678\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"convex_area\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 13041,\n        \"min\": 41290,\n        \"max\": 132478,\n        \"num_unique_values\": 1276,\n        \"samples\": [\n          94167,\n          70896,\n          90662\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"extent\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.051630142771004466,\n        \"min\": 0.5003,\n        \"max\": 0.8204,\n        \"num_unique_values\": 908,\n        \"samples\": [\n          0.5775,\n          0.7447,\n          0.7506\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"aspect_ratio\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.23782539746676157,\n        \"min\": 1.1585,\n        \"max\": 3.0693,\n        \"num_unique_values\": 1197,\n        \"samples\": [\n          2.0206,\n          1.7592,\n          1.8587\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"roundness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.21071584192191556,\n        \"min\": 0.122,\n        \"max\": 0.9336,\n        \"num_unique_values\": 1149,\n        \"samples\": [\n          0.8007,\n          0.4883,\n          0.7076\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"compactness\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.04337529200124845,\n        \"min\": 0.5649,\n        \"max\": 0.8695,\n        \"num_unique_values\": 871,\n        \"samples\": [\n          0.8052,\n          0.7549,\n          0.7398\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shapefactor_1\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.0007506278932296684,\n        \"min\": 0.004,\n        \"max\": 0.01,\n        \"num_unique_values\": 47,\n        \"samples\": [\n          0.0063,\n          0.0077,\n          0.0052\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shapefactor_2\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.00033153766979532415,\n        \"min\": 0.0024,\n        \"max\": 0.0053,\n        \"num_unique_values\": 25,\n        \"samples\": [\n          0.0032,\n          0.0038,\n          0.0033\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shapefactor_3\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.06251397711115424,\n        \"min\": 0.3191,\n        \"max\": 0.7561,\n        \"num_unique_values\": 958,\n        \"samples\": [\n          0.5596,\n          0.4555,\n          0.6058\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"shapefactor_4\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0.050769948492337715,\n        \"min\": 0.6414,\n        \"max\": 0.9989,\n        \"num_unique_values\": 709,\n        \"samples\": [\n          0.9802,\n          0.9428,\n          0.9653\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"target\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          0,\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df_train.isna().sum()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 610
        },
        "id": "2ye4v638uT0E",
        "outputId": "542688dd-75d4-4814-ba3e-563f787340d5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "area             0\n",
              "perimeter        0\n",
              "major_axis       0\n",
              "minor_axis       0\n",
              "eccentricity     0\n",
              "eqdiasq          0\n",
              "solidity         0\n",
              "convex_area      0\n",
              "extent           0\n",
              "aspect_ratio     0\n",
              "roundness        0\n",
              "compactness      0\n",
              "shapefactor_1    0\n",
              "shapefactor_2    0\n",
              "shapefactor_3    0\n",
              "shapefactor_4    0\n",
              "target           0\n",
              "dtype: int64"
            ],
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>area</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>perimeter</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>major_axis</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>minor_axis</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eccentricity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>eqdiasq</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>solidity</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>convex_area</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>extent</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>aspect_ratio</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>roundness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>compactness</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shapefactor_1</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shapefactor_2</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shapefactor_3</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>shapefactor_4</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>target</th>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div><br><label><b>dtype:</b> int64</label>"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "X = df_train.drop(columns='target')\n",
        "y = df_train['target']\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "qSgVYTpfuj6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "x_train_norm = scaler.fit_transform(x_train)\n",
        "x_test_norm = scaler.transform(x_test)"
      ],
      "metadata": {
        "id": "spaOEYZzvW9p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Baseline"
      ],
      "metadata": {
        "id": "VLCWSnV6v6JQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)\n",
        "model.fit(x_train_norm, y_train)\n",
        "\n",
        "y_pred = model.predict(x_test_norm)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TBtES8-PvWRG",
        "outputId": "75b5bc98-2dbf-4761-ce81-8e4d27a97035"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8604651162790697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Catboost"
      ],
      "metadata": {
        "id": "bERC0maAwLUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install catboost"
      ],
      "metadata": {
        "id": "xbpY-q3iwP7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import catboost\n",
        "from catboost import CatBoostClassifier\n",
        "\n",
        "model = CatBoostClassifier(\n",
        "    iterations=1000,      # сколько деревьев\n",
        "    learning_rate=0.1,    # скорость обучения\n",
        "    depth=6,              # глубина деревьев\n",
        "    eval_metric='Accuracy', # метрика для валидации\n",
        "    verbose=100           # выводить лог каждые 100 итераций\n",
        ")\n",
        "\n",
        "model.fit(x_train_norm, y_train, eval_set=(x_test_norm, y_test), early_stopping_rounds=100)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NmMMNTE3wNj8",
        "outputId": "0702f9c3-32ae-4f14-d8d2-b5f7971a9c13"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0:\tlearn: 0.8601942\ttest: 0.8604651\tbest: 0.8604651 (0)\ttotal: 5.25ms\tremaining: 5.25s\n",
            "100:\tlearn: 0.9650485\ttest: 0.8643411\tbest: 0.8682171 (92)\ttotal: 534ms\tremaining: 4.75s\n",
            "Stopped by overfitting detector  (100 iterations wait)\n",
            "\n",
            "bestTest = 0.8682170543\n",
            "bestIteration = 92\n",
            "\n",
            "Shrink model to first 93 iterations.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7aa71c7fce50>"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(x_test_norm)\n",
        "\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GiHC-Kjnwszl",
        "outputId": "00f86d25-b885-49af-89aa-d2386a0c9395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8682170542635659\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.get_feature_importance()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MBTEES8Vw2m5",
        "outputId": "51e67c50-329d-488f-b33b-801d0410bf44"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 4.84380498,  4.32221351,  5.3485225 ,  7.45771523,  3.98296599,\n",
              "        5.84377718,  6.78647806,  6.82572009,  7.68919654,  5.0813057 ,\n",
              "        6.52007056,  5.06521019, 10.35060351,  1.56910602,  6.9095296 ,\n",
              "       11.40378034])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Подбор гиперпарамтеров"
      ],
      "metadata": {
        "id": "QToFaR7fxJe5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install optuna"
      ],
      "metadata": {
        "id": "jS5wQWCRxNfD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        'depth': trial.suggest_int('depth', 4, 10),\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.3),\n",
        "        'iterations': trial.suggest_int('iterations', 500, 1500),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 10),\n",
        "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 2),\n",
        "        'border_count': trial.suggest_int('border_count', 32, 255),\n",
        "        'random_strength': trial.suggest_float('random_strength', 1e-9, 10),\n",
        "        'verbose': 0,\n",
        "        'random_seed': 42\n",
        "    }\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "    score = cross_val_score(model, X, y, scoring='accuracy', cv=3).mean()\n",
        "    return score\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(study.best_params)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ULnEFKRNxPD8",
        "outputId": "82c3eb81-06d4-4839-cc23-a76c28b7fd25"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-26 20:23:59,623] A new study created in memory with name: no-name-136191ab-1791-4e4d-8748-66c460457273\n",
            "[I 2025-04-26 20:24:34,257] Trial 0 finished with value: 0.8649120904934859 and parameters: {'depth': 8, 'learning_rate': 0.160655565525162, 'iterations': 1177, 'l2_leaf_reg': 6.339233335543313, 'bagging_temperature': 0.20311643105228572, 'border_count': 110, 'random_strength': 1.1281492649159823}. Best is trial 0 with value: 0.8649120904934859.\n",
            "[I 2025-04-26 20:24:48,836] Trial 1 finished with value: 0.8641260548237293 and parameters: {'depth': 8, 'learning_rate': 0.2795293818484768, 'iterations': 658, 'l2_leaf_reg': 4.564917587128414, 'bagging_temperature': 1.8038967348993573, 'border_count': 114, 'random_strength': 6.6732706533586486}. Best is trial 0 with value: 0.8649120904934859.\n",
            "[I 2025-04-26 20:24:55,016] Trial 2 finished with value: 0.8618167362353408 and parameters: {'depth': 5, 'learning_rate': 0.14425327602162744, 'iterations': 741, 'l2_leaf_reg': 3.646166481098134, 'bagging_temperature': 1.8102830513387507, 'border_count': 229, 'random_strength': 4.220571987323037}. Best is trial 0 with value: 0.8649120904934859.\n",
            "[I 2025-04-26 20:25:12,867] Trial 3 finished with value: 0.8618095083211363 and parameters: {'depth': 7, 'learning_rate': 0.2530458333319932, 'iterations': 988, 'l2_leaf_reg': 4.295225458359772, 'bagging_temperature': 1.749340689296507, 'border_count': 159, 'random_strength': 9.140189963126588}. Best is trial 0 with value: 0.8649120904934859.\n",
            "[I 2025-04-26 20:25:25,462] Trial 4 finished with value: 0.863365316853689 and parameters: {'depth': 7, 'learning_rate': 0.1801386878096134, 'iterations': 863, 'l2_leaf_reg': 5.39142421568087, 'bagging_temperature': 0.6522645848096589, 'border_count': 128, 'random_strength': 9.488748361954281}. Best is trial 0 with value: 0.8649120904934859.\n",
            "[I 2025-04-26 20:27:28,939] Trial 5 finished with value: 0.8672467067815904 and parameters: {'depth': 10, 'learning_rate': 0.07998982828128541, 'iterations': 978, 'l2_leaf_reg': 1.633107253645535, 'bagging_temperature': 0.7571791849244496, 'border_count': 227, 'random_strength': 2.926905021808559}. Best is trial 5 with value: 0.8672467067815904.\n",
            "[I 2025-04-26 20:27:53,931] Trial 6 finished with value: 0.8594821199472363 and parameters: {'depth': 7, 'learning_rate': 0.09860100233533078, 'iterations': 1037, 'l2_leaf_reg': 8.734128385366665, 'bagging_temperature': 1.9803306085089118, 'border_count': 237, 'random_strength': 9.892202664994656}. Best is trial 5 with value: 0.8672467067815904.\n",
            "[I 2025-04-26 20:28:53,488] Trial 7 finished with value: 0.8602555067671348 and parameters: {'depth': 9, 'learning_rate': 0.29049641610635957, 'iterations': 825, 'l2_leaf_reg': 1.576115559528207, 'bagging_temperature': 1.2240500490535304, 'border_count': 218, 'random_strength': 3.4391991331893697}. Best is trial 5 with value: 0.8672467067815904.\n",
            "[I 2025-04-26 20:29:44,860] Trial 8 finished with value: 0.8672467067815904 and parameters: {'depth': 8, 'learning_rate': 0.22643397872287718, 'iterations': 1483, 'l2_leaf_reg': 7.08906347096412, 'bagging_temperature': 1.0509828101654797, 'border_count': 195, 'random_strength': 8.138971448122602}. Best is trial 5 with value: 0.8672467067815904.\n",
            "[I 2025-04-26 20:29:50,702] Trial 9 finished with value: 0.8618113152996872 and parameters: {'depth': 7, 'learning_rate': 0.2671194474912364, 'iterations': 1025, 'l2_leaf_reg': 6.150426814066758, 'bagging_temperature': 1.5869868851809539, 'border_count': 37, 'random_strength': 2.9582505402553587}. Best is trial 5 with value: 0.8672467067815904.\n",
            "[I 2025-04-26 20:30:43,670] Trial 10 finished with value: 0.8687934804213874 and parameters: {'depth': 10, 'learning_rate': 0.022949509013782683, 'iterations': 510, 'l2_leaf_reg': 1.2505199129562872, 'bagging_temperature': 0.553824622871204, 'border_count': 177, 'random_strength': 1.295507135778855}. Best is trial 10 with value: 0.8687934804213874.\n",
            "[I 2025-04-26 20:31:33,730] Trial 11 finished with value: 0.8687970943784897 and parameters: {'depth': 10, 'learning_rate': 0.010659084234953481, 'iterations': 513, 'l2_leaf_reg': 1.0639885790536452, 'bagging_temperature': 0.49657626750925343, 'border_count': 178, 'random_strength': 0.0338071529056041}. Best is trial 11 with value: 0.8687970943784897.\n",
            "[I 2025-04-26 20:32:22,311] Trial 12 finished with value: 0.8672394788673858 and parameters: {'depth': 10, 'learning_rate': 0.023979541426369516, 'iterations': 518, 'l2_leaf_reg': 2.645709925753969, 'bagging_temperature': 0.1558557679852075, 'border_count': 170, 'random_strength': 0.0437866611606168}. Best is trial 11 with value: 0.8687970943784897.\n",
            "[I 2025-04-26 20:32:24,984] Trial 13 finished with value: 0.8688007083355921 and parameters: {'depth': 4, 'learning_rate': 0.03190916022574526, 'iterations': 503, 'l2_leaf_reg': 1.1267522415597284, 'bagging_temperature': 0.5331106768649568, 'border_count': 177, 'random_strength': 1.3914035601820731}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:32:27,291] Trial 14 finished with value: 0.8649138974720371 and parameters: {'depth': 4, 'learning_rate': 0.05948233439239986, 'iterations': 629, 'l2_leaf_reg': 3.0238380839869627, 'bagging_temperature': 0.4020427395044802, 'border_count': 77, 'random_strength': 0.24019881257604148}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:32:33,759] Trial 15 finished with value: 0.8618167362353409 and parameters: {'depth': 5, 'learning_rate': 0.051436970773277614, 'iterations': 627, 'l2_leaf_reg': 2.318937336758134, 'bagging_temperature': 0.889047361694949, 'border_count': 199, 'random_strength': 5.8255123290885304}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:32:36,202] Trial 16 finished with value: 0.851719340091433 and parameters: {'depth': 4, 'learning_rate': 0.12045609681994617, 'iterations': 500, 'l2_leaf_reg': 1.0783512596437905, 'bagging_temperature': 0.3551525933163628, 'border_count': 142, 'random_strength': 1.7980885516697267}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:32:57,258] Trial 17 finished with value: 0.8687989013570409 and parameters: {'depth': 6, 'learning_rate': 0.014306380909476866, 'iterations': 1345, 'l2_leaf_reg': 9.802293981549862, 'bagging_temperature': 0.004839663006661499, 'border_count': 252, 'random_strength': 2.1015365335715153}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:33:11,268] Trial 18 finished with value: 0.8641405106521386 and parameters: {'depth': 5, 'learning_rate': 0.05192582778117687, 'iterations': 1404, 'l2_leaf_reg': 9.65697209389028, 'bagging_temperature': 0.028215574309285823, 'border_count': 255, 'random_strength': 2.1683928585825685}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:33:29,682] Trial 19 finished with value: 0.8656963191846913 and parameters: {'depth': 6, 'learning_rate': 0.19324028375242241, 'iterations': 1258, 'l2_leaf_reg': 8.021650496088615, 'bagging_temperature': 0.28090052250547787, 'border_count': 255, 'random_strength': 4.933356824206933}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:33:39,381] Trial 20 finished with value: 0.8625847021195859 and parameters: {'depth': 6, 'learning_rate': 0.1019301323617526, 'iterations': 1260, 'l2_leaf_reg': 9.921045183370847, 'bagging_temperature': 0.05815417609967769, 'border_count': 83, 'random_strength': 3.8785046277010258}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:33:48,926] Trial 21 finished with value: 0.8688007083355921 and parameters: {'depth': 6, 'learning_rate': 0.01235133442264387, 'iterations': 708, 'l2_leaf_reg': 2.176166225186432, 'bagging_temperature': 0.5165067144824863, 'border_count': 198, 'random_strength': 0.7091843973691918}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:33:57,584] Trial 22 finished with value: 0.8672503207386928 and parameters: {'depth': 6, 'learning_rate': 0.029177713317884307, 'iterations': 756, 'l2_leaf_reg': 3.3330350662812966, 'bagging_temperature': 1.0696829840701687, 'border_count': 204, 'random_strength': 1.9752318641848223}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:34:05,650] Trial 23 finished with value: 0.855604343976437 and parameters: {'depth': 4, 'learning_rate': 0.06242721252954743, 'iterations': 1164, 'l2_leaf_reg': 7.792804173880839, 'bagging_temperature': 1.3485382094230483, 'border_count': 205, 'random_strength': 0.8571482827714634}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:34:10,244] Trial 24 finished with value: 0.8672412858459371 and parameters: {'depth': 5, 'learning_rate': 0.03937731137076589, 'iterations': 698, 'l2_leaf_reg': 2.355618626503306, 'bagging_temperature': 0.771844808847912, 'border_count': 155, 'random_strength': 2.5812499992484224}. Best is trial 13 with value: 0.8688007083355921.\n",
            "[I 2025-04-26 20:34:20,983] Trial 25 finished with value: 0.8726820982634936 and parameters: {'depth': 6, 'learning_rate': 0.010880662927983162, 'iterations': 867, 'l2_leaf_reg': 4.200381089787874, 'bagging_temperature': 0.5196439794994354, 'border_count': 181, 'random_strength': 1.4728159353238826}. Best is trial 25 with value: 0.8726820982634936.\n",
            "[I 2025-04-26 20:34:28,904] Trial 26 finished with value: 0.8594839269257873 and parameters: {'depth': 5, 'learning_rate': 0.08206446639089592, 'iterations': 879, 'l2_leaf_reg': 4.040983867735929, 'bagging_temperature': 0.5655963840031941, 'border_count': 183, 'random_strength': 1.0180425113613099}. Best is trial 25 with value: 0.8726820982634936.\n",
            "[I 2025-04-26 20:34:34,413] Trial 27 finished with value: 0.863365316853689 and parameters: {'depth': 6, 'learning_rate': 0.08138821645779437, 'iterations': 601, 'l2_leaf_reg': 4.896293874639902, 'bagging_temperature': 0.8847900026780184, 'border_count': 147, 'random_strength': 4.4786742339507}. Best is trial 25 with value: 0.8726820982634936.\n",
            "[I 2025-04-26 20:34:40,293] Trial 28 finished with value: 0.8594821199472363 and parameters: {'depth': 4, 'learning_rate': 0.03781883597323628, 'iterations': 789, 'l2_leaf_reg': 2.226520309029538, 'bagging_temperature': 0.44286247105442306, 'border_count': 189, 'random_strength': 0.7318693621462671}. Best is trial 25 with value: 0.8726820982634936.\n",
            "[I 2025-04-26 20:35:01,798] Trial 29 finished with value: 0.8641387036735874 and parameters: {'depth': 8, 'learning_rate': 0.13322604280764044, 'iterations': 921, 'l2_leaf_reg': 1.9254556037040254, 'bagging_temperature': 0.26019628529035604, 'border_count': 129, 'random_strength': 1.4176922820863829}. Best is trial 25 with value: 0.8726820982634936.\n",
            "[I 2025-04-26 20:35:08,184] Trial 30 finished with value: 0.864145931587792 and parameters: {'depth': 5, 'learning_rate': 0.06768539822050948, 'iterations': 689, 'l2_leaf_reg': 3.592245131162565, 'bagging_temperature': 0.6969683989720187, 'border_count': 163, 'random_strength': 6.311913048465028}. Best is trial 25 with value: 0.8726820982634936.\n",
            "[I 2025-04-26 20:35:24,682] Trial 31 finished with value: 0.8687970943784897 and parameters: {'depth': 6, 'learning_rate': 0.014627320930680083, 'iterations': 1160, 'l2_leaf_reg': 5.974917963444993, 'bagging_temperature': 0.23301045062285675, 'border_count': 239, 'random_strength': 1.6210708026477358}. Best is trial 25 with value: 0.8726820982634936.\n",
            "[I 2025-04-26 20:35:37,258] Trial 32 finished with value: 0.8734536781048409 and parameters: {'depth': 6, 'learning_rate': 0.013614207410835799, 'iterations': 917, 'l2_leaf_reg': 6.769334732137483, 'bagging_temperature': 0.08920921606917354, 'border_count': 217, 'random_strength': 2.202551055626916}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:35:57,262] Trial 33 finished with value: 0.8625883160766882 and parameters: {'depth': 6, 'learning_rate': 0.03626123826258993, 'iterations': 920, 'l2_leaf_reg': 7.0603848507951845, 'bagging_temperature': 0.14043823310361886, 'border_count': 212, 'random_strength': 0.7820956107762222}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:36:21,680] Trial 34 finished with value: 0.8587087331273379 and parameters: {'depth': 7, 'learning_rate': 0.04337593965436255, 'iterations': 1086, 'l2_leaf_reg': 5.152527352723863, 'bagging_temperature': 0.6094585815747462, 'border_count': 222, 'random_strength': 3.434269753794695}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:36:25,749] Trial 35 finished with value: 0.8726748703492889 and parameters: {'depth': 5, 'learning_rate': 0.010251605066100334, 'iterations': 569, 'l2_leaf_reg': 6.739004740585771, 'bagging_temperature': 0.38571438714238887, 'border_count': 185, 'random_strength': 2.3061345529387083}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:36:29,637] Trial 36 finished with value: 0.8633635098751378 and parameters: {'depth': 5, 'learning_rate': 0.16267439167925873, 'iterations': 574, 'l2_leaf_reg': 7.014137267965406, 'bagging_temperature': 0.3477242417125963, 'border_count': 168, 'random_strength': 2.5602225958540648}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:36:33,938] Trial 37 finished with value: 0.8633689308107911 and parameters: {'depth': 4, 'learning_rate': 0.10120802700693478, 'iterations': 577, 'l2_leaf_reg': 5.790935985365066, 'bagging_temperature': 0.1386314718545661, 'border_count': 184, 'random_strength': 3.273161200793909}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:36:43,391] Trial 38 finished with value: 0.8587087331273379 and parameters: {'depth': 5, 'learning_rate': 0.0751771145184908, 'iterations': 833, 'l2_leaf_reg': 6.712987346512441, 'bagging_temperature': 0.8440221402226767, 'border_count': 129, 'random_strength': 7.650311913420994}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:36:48,237] Trial 39 finished with value: 0.8579281183932347 and parameters: {'depth': 4, 'learning_rate': 0.20999628032753323, 'iterations': 768, 'l2_leaf_reg': 7.8267858424123045, 'bagging_temperature': 0.3302525528765293, 'border_count': 110, 'random_strength': 3.9767210307289345}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:36:57,259] Trial 40 finished with value: 0.8587051191702354 and parameters: {'depth': 5, 'learning_rate': 0.028983151129347857, 'iterations': 1089, 'l2_leaf_reg': 6.496175364034374, 'bagging_temperature': 0.4157571039859536, 'border_count': 234, 'random_strength': 2.8126883206076547}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:37:07,026] Trial 41 finished with value: 0.8726802912849424 and parameters: {'depth': 6, 'learning_rate': 0.01189833121958117, 'iterations': 693, 'l2_leaf_reg': 4.141382861016108, 'bagging_temperature': 0.48102454866696936, 'border_count': 211, 'random_strength': 2.314498602330919}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:37:21,337] Trial 42 finished with value: 0.8656927052275889 and parameters: {'depth': 7, 'learning_rate': 0.04707271367926544, 'iterations': 661, 'l2_leaf_reg': 4.543208481040615, 'bagging_temperature': 0.6781182576556551, 'border_count': 215, 'random_strength': 2.1027894919038923}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:37:40,891] Trial 43 finished with value: 0.8664642850689361 and parameters: {'depth': 7, 'learning_rate': 0.027470966877619147, 'iterations': 938, 'l2_leaf_reg': 4.073015341640495, 'bagging_temperature': 0.2051916755810681, 'border_count': 192, 'random_strength': 1.4346012928285676}. Best is trial 32 with value: 0.8734536781048409.\n",
            "[I 2025-04-26 20:38:19,364] Trial 44 finished with value: 0.8750076796588425 and parameters: {'depth': 9, 'learning_rate': 0.013474519950993427, 'iterations': 571, 'l2_leaf_reg': 5.556522643022767, 'bagging_temperature': 0.4847632351487044, 'border_count': 208, 'random_strength': 2.4587408499630583}. Best is trial 44 with value: 0.8750076796588425.\n",
            "[I 2025-04-26 20:39:23,438] Trial 45 finished with value: 0.8695722881769393 and parameters: {'depth': 9, 'learning_rate': 0.015511449130402644, 'iterations': 817, 'l2_leaf_reg': 5.3830055862397455, 'bagging_temperature': 0.4650027625011838, 'border_count': 226, 'random_strength': 2.528742821720461}. Best is trial 44 with value: 0.8750076796588425.\n",
            "[I 2025-04-26 20:40:34,254] Trial 46 finished with value: 0.8734518711262899 and parameters: {'depth': 9, 'learning_rate': 0.052459504501126145, 'iterations': 731, 'l2_leaf_reg': 4.628779560559895, 'bagging_temperature': 0.09985048910464367, 'border_count': 211, 'random_strength': 3.4622288332839943}. Best is trial 44 with value: 0.8750076796588425.\n",
            "[I 2025-04-26 20:41:47,950] Trial 47 finished with value: 0.8664642850689361 and parameters: {'depth': 9, 'learning_rate': 0.056014608152422735, 'iterations': 871, 'l2_leaf_reg': 4.657992464805112, 'bagging_temperature': 1.2278194740996242, 'border_count': 208, 'random_strength': 3.2014265863310314}. Best is trial 44 with value: 0.8750076796588425.\n",
            "[I 2025-04-26 20:42:22,839] Trial 48 finished with value: 0.8625901230552393 and parameters: {'depth': 8, 'learning_rate': 0.24745304300047521, 'iterations': 720, 'l2_leaf_reg': 5.664511449146879, 'bagging_temperature': 0.11542813651691715, 'border_count': 218, 'random_strength': 3.7284380346253796}. Best is trial 44 with value: 0.8750076796588425.\n",
            "[I 2025-04-26 20:44:37,381] Trial 49 finished with value: 0.8672412858459371 and parameters: {'depth': 9, 'learning_rate': 0.023514388455683433, 'iterations': 973, 'l2_leaf_reg': 3.7678202057461117, 'bagging_temperature': 0.7707437329363118, 'border_count': 245, 'random_strength': 4.718626854505505}. Best is trial 44 with value: 0.8750076796588425.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'depth': 9, 'learning_rate': 0.013474519950993427, 'iterations': 571, 'l2_leaf_reg': 5.556522643022767, 'bagging_temperature': 0.4847632351487044, 'border_count': 208, 'random_strength': 2.4587408499630583}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"iterations\": 10000,\n",
        "        \"early_stopping_rounds\": 100,\n",
        "        \"depth\": trial.suggest_int(\"depth\", 4, 10),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
        "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
        "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n",
        "        \"random_strength\": trial.suggest_float(\"random_strength\", 1, 10),\n",
        "        \"loss_function\": \"Logloss\",\n",
        "        \"eval_metric\": \"Accuracy\",\n",
        "        \"verbose\": 0,\n",
        "        \"task_type\": \"GPU\",\n",
        "        \"devices\": \"0\"\n",
        "    }\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Обучаем модель\n",
        "    model.fit(x_train_norm, y_train, eval_set=(x_test_norm, y_test), use_best_model=True)\n",
        "\n",
        "    preds = model.predict(x_test_norm)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"\\nЛучшие параметры:\")\n",
        "print(study.best_params)\n",
        "print(\"\\nЛучшая точность:\", study.best_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzICShfi0BYG",
        "outputId": "d9b53e66-d704-47d4-90f4-0e93b852a06c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-26 20:53:11,339] A new study created in memory with name: no-name-78986c58-bbd5-4795-9bcc-8e4ef4f5449c\n",
            "[I 2025-04-26 20:53:14,356] Trial 0 finished with value: 0.8604651162790697 and parameters: {'depth': 5, 'learning_rate': 0.045272466382665265, 'l2_leaf_reg': 9.115523150728121, 'bagging_temperature': 0.746366364915276, 'random_strength': 5.449514247357252}. Best is trial 0 with value: 0.8604651162790697.\n",
            "[I 2025-04-26 20:53:44,819] Trial 1 finished with value: 0.8604651162790697 and parameters: {'depth': 10, 'learning_rate': 0.06216291024989967, 'l2_leaf_reg': 7.843710861274478, 'bagging_temperature': 0.944327367193749, 'random_strength': 2.188217408277361}. Best is trial 0 with value: 0.8604651162790697.\n",
            "[I 2025-04-26 20:53:52,059] Trial 2 finished with value: 0.8604651162790697 and parameters: {'depth': 8, 'learning_rate': 0.04387300338709352, 'l2_leaf_reg': 1.5945893858336906, 'bagging_temperature': 0.6327092644026538, 'random_strength': 1.3086402863714661}. Best is trial 0 with value: 0.8604651162790697.\n",
            "[I 2025-04-26 20:53:55,077] Trial 3 finished with value: 0.8643410852713178 and parameters: {'depth': 5, 'learning_rate': 0.02297985055847151, 'l2_leaf_reg': 5.352258039323224, 'bagging_temperature': 0.4949131414199709, 'random_strength': 4.257735210735131}. Best is trial 3 with value: 0.8643410852713178.\n",
            "[I 2025-04-26 20:53:59,634] Trial 4 finished with value: 0.8682170542635659 and parameters: {'depth': 7, 'learning_rate': 0.08502721584843707, 'l2_leaf_reg': 3.5662286035166515, 'bagging_temperature': 0.39932495191888695, 'random_strength': 9.550674346719358}. Best is trial 4 with value: 0.8682170542635659.\n",
            "[I 2025-04-26 20:54:02,191] Trial 5 finished with value: 0.8643410852713178 and parameters: {'depth': 5, 'learning_rate': 0.017387259791055883, 'l2_leaf_reg': 5.408910797710475, 'bagging_temperature': 0.790245422476443, 'random_strength': 7.573218644271012}. Best is trial 4 with value: 0.8682170542635659.\n",
            "[I 2025-04-26 20:54:07,645] Trial 6 finished with value: 0.8565891472868217 and parameters: {'depth': 7, 'learning_rate': 0.03358857605991912, 'l2_leaf_reg': 7.956187256421509, 'bagging_temperature': 0.8203366766280848, 'random_strength': 1.3801051047468393}. Best is trial 4 with value: 0.8682170542635659.\n",
            "[I 2025-04-26 20:54:10,068] Trial 7 finished with value: 0.8604651162790697 and parameters: {'depth': 5, 'learning_rate': 0.022258839111097047, 'l2_leaf_reg': 2.1055657727299515, 'bagging_temperature': 0.41472819684098505, 'random_strength': 1.3226089949702269}. Best is trial 4 with value: 0.8682170542635659.\n",
            "[I 2025-04-26 20:54:21,520] Trial 8 finished with value: 0.872093023255814 and parameters: {'depth': 9, 'learning_rate': 0.05960265301177632, 'l2_leaf_reg': 4.1278343877439845, 'bagging_temperature': 0.47828097228965516, 'random_strength': 7.237926047347513}. Best is trial 8 with value: 0.872093023255814.\n",
            "[I 2025-04-26 20:54:34,057] Trial 9 finished with value: 0.8565891472868217 and parameters: {'depth': 9, 'learning_rate': 0.0656187995235443, 'l2_leaf_reg': 5.894077271264377, 'bagging_temperature': 0.6118011745733279, 'random_strength': 1.0849685722393985}. Best is trial 8 with value: 0.872093023255814.\n",
            "[I 2025-04-26 20:54:54,012] Trial 10 finished with value: 0.8604651162790697 and parameters: {'depth': 10, 'learning_rate': 0.08398603808180079, 'l2_leaf_reg': 3.8042432565592867, 'bagging_temperature': 0.07015603015415939, 'random_strength': 7.412950808502737}. Best is trial 8 with value: 0.872093023255814.\n",
            "[I 2025-04-26 20:54:58,884] Trial 11 finished with value: 0.8682170542635659 and parameters: {'depth': 7, 'learning_rate': 0.0989742389282502, 'l2_leaf_reg': 3.500477865386276, 'bagging_temperature': 0.2579483268038228, 'random_strength': 9.825774178878476}. Best is trial 8 with value: 0.872093023255814.\n",
            "[I 2025-04-26 20:55:06,223] Trial 12 finished with value: 0.872093023255814 and parameters: {'depth': 8, 'learning_rate': 0.07836295865222159, 'l2_leaf_reg': 3.5527723873912467, 'bagging_temperature': 0.26990470172538034, 'random_strength': 9.863026769692123}. Best is trial 8 with value: 0.872093023255814.\n",
            "[I 2025-04-26 20:55:12,493] Trial 13 finished with value: 0.875968992248062 and parameters: {'depth': 8, 'learning_rate': 0.07467512885213419, 'l2_leaf_reg': 4.579248740631226, 'bagging_temperature': 0.22503495936094642, 'random_strength': 8.038749733809894}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:55:31,305] Trial 14 finished with value: 0.8682170542635659 and parameters: {'depth': 9, 'learning_rate': 0.0684471537486399, 'l2_leaf_reg': 6.067383772539529, 'bagging_temperature': 0.0016168792010207156, 'random_strength': 7.885759178364225}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:55:47,659] Trial 15 finished with value: 0.8682170542635659 and parameters: {'depth': 8, 'learning_rate': 0.05488746066450241, 'l2_leaf_reg': 4.239425699195241, 'bagging_temperature': 0.20016979272322682, 'random_strength': 6.39314943468241}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:56:08,578] Trial 16 finished with value: 0.872093023255814 and parameters: {'depth': 9, 'learning_rate': 0.09739209493758169, 'l2_leaf_reg': 2.525850467362444, 'bagging_temperature': 0.13921739034419567, 'random_strength': 8.556288540101885}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:56:11,513] Trial 17 finished with value: 0.8643410852713178 and parameters: {'depth': 6, 'learning_rate': 0.05351773173106423, 'l2_leaf_reg': 6.7964393356702955, 'bagging_temperature': 0.403717201416674, 'random_strength': 6.109078386990938}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:56:21,964] Trial 18 finished with value: 0.8565891472868217 and parameters: {'depth': 9, 'learning_rate': 0.07352149305815935, 'l2_leaf_reg': 4.537465309088617, 'bagging_temperature': 0.28934390086826356, 'random_strength': 4.321982626618185}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:56:24,520] Trial 19 finished with value: 0.8643410852713178 and parameters: {'depth': 4, 'learning_rate': 0.08843524613027226, 'l2_leaf_reg': 6.969732355016625, 'bagging_temperature': 0.6340860905638692, 'random_strength': 8.613355826441369}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:56:41,952] Trial 20 finished with value: 0.8682170542635659 and parameters: {'depth': 10, 'learning_rate': 0.03721744539927068, 'l2_leaf_reg': 2.442920976852729, 'bagging_temperature': 0.5226588887339372, 'random_strength': 6.747287120060489}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:56:49,117] Trial 21 finished with value: 0.8682170542635659 and parameters: {'depth': 8, 'learning_rate': 0.0754228007846658, 'l2_leaf_reg': 4.731729064033006, 'bagging_temperature': 0.3098376461128479, 'random_strength': 8.98236331146679}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:56:55,366] Trial 22 finished with value: 0.8643410852713178 and parameters: {'depth': 8, 'learning_rate': 0.07733991503775653, 'l2_leaf_reg': 3.0631314548691666, 'bagging_temperature': 0.16006871908794557, 'random_strength': 8.239687045768491}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:57:01,753] Trial 23 finished with value: 0.8643410852713178 and parameters: {'depth': 7, 'learning_rate': 0.06139029530451763, 'l2_leaf_reg': 1.3499320682142262, 'bagging_temperature': 0.34046340419418, 'random_strength': 9.992903928316663}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:57:08,352] Trial 24 finished with value: 0.8643410852713178 and parameters: {'depth': 8, 'learning_rate': 0.08974120241519715, 'l2_leaf_reg': 4.857557114342347, 'bagging_temperature': 0.20976761989076909, 'random_strength': 9.1973374360543}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:57:19,470] Trial 25 finished with value: 0.8682170542635659 and parameters: {'depth': 9, 'learning_rate': 0.07137837522882778, 'l2_leaf_reg': 3.0291553891359917, 'bagging_temperature': 0.4716802410656411, 'random_strength': 7.138504599114635}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:57:23,629] Trial 26 finished with value: 0.872093023255814 and parameters: {'depth': 6, 'learning_rate': 0.058246385882616235, 'l2_leaf_reg': 4.329501433564984, 'bagging_temperature': 0.055297759517176526, 'random_strength': 5.233492969094446}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:57:30,331] Trial 27 finished with value: 0.872093023255814 and parameters: {'depth': 8, 'learning_rate': 0.07852316724940664, 'l2_leaf_reg': 3.85693433885866, 'bagging_temperature': 0.5681023797201923, 'random_strength': 8.95188639211704}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:57:42,606] Trial 28 finished with value: 0.8643410852713178 and parameters: {'depth': 9, 'learning_rate': 0.04965574827797897, 'l2_leaf_reg': 6.3150920911449955, 'bagging_temperature': 0.34831057808165916, 'random_strength': 8.075622538995386}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:57:48,091] Trial 29 finished with value: 0.8682170542635659 and parameters: {'depth': 6, 'learning_rate': 0.06711437993469066, 'l2_leaf_reg': 9.790492135140477, 'bagging_temperature': 0.23609721183596666, 'random_strength': 5.299636296682799}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:58:05,036] Trial 30 finished with value: 0.8643410852713178 and parameters: {'depth': 10, 'learning_rate': 0.04632922537598453, 'l2_leaf_reg': 3.117077928394738, 'bagging_temperature': 0.10470352437832298, 'random_strength': 6.028115316774585}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:58:20,223] Trial 31 finished with value: 0.8643410852713178 and parameters: {'depth': 9, 'learning_rate': 0.0981262502210558, 'l2_leaf_reg': 2.4004479517293107, 'bagging_temperature': 0.14825219649248902, 'random_strength': 8.813164452406136}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:58:42,663] Trial 32 finished with value: 0.8643410852713178 and parameters: {'depth': 9, 'learning_rate': 0.09081405743276416, 'l2_leaf_reg': 2.75346988303935, 'bagging_temperature': 0.1422633906971974, 'random_strength': 8.350679071883565}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:58:53,578] Trial 33 finished with value: 0.8643410852713178 and parameters: {'depth': 8, 'learning_rate': 0.08186188414912905, 'l2_leaf_reg': 1.8021555396882838, 'bagging_temperature': 0.9648090968518882, 'random_strength': 9.404024745370288}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:59:14,098] Trial 34 finished with value: 0.8565891472868217 and parameters: {'depth': 10, 'learning_rate': 0.09293106267382441, 'l2_leaf_reg': 1.1223601569772559, 'bagging_temperature': 0.02516316303833714, 'random_strength': 6.921320007322748}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:59:18,097] Trial 35 finished with value: 0.8643410852713178 and parameters: {'depth': 7, 'learning_rate': 0.06349997435377823, 'l2_leaf_reg': 4.908696187047602, 'bagging_temperature': 0.10344213453117458, 'random_strength': 7.737324481167503}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:59:25,221] Trial 36 finished with value: 0.8643410852713178 and parameters: {'depth': 8, 'learning_rate': 0.0841820579273745, 'l2_leaf_reg': 3.994412896180507, 'bagging_temperature': 0.4652398507525761, 'random_strength': 8.330071336217326}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:59:46,965] Trial 37 finished with value: 0.872093023255814 and parameters: {'depth': 9, 'learning_rate': 0.09421884082301614, 'l2_leaf_reg': 5.272459137988079, 'bagging_temperature': 0.7232216298459575, 'random_strength': 9.492825040459826}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 20:59:57,862] Trial 38 finished with value: 0.8604651162790697 and parameters: {'depth': 8, 'learning_rate': 0.07140133533956264, 'l2_leaf_reg': 3.313221445835624, 'bagging_temperature': 0.35070358827302034, 'random_strength': 3.6997383945912996}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:11,951] Trial 39 finished with value: 0.8682170542635659 and parameters: {'depth': 9, 'learning_rate': 0.038129384781557835, 'l2_leaf_reg': 2.0808069071049533, 'bagging_temperature': 0.8827996732648437, 'random_strength': 7.455586075715741}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:30,473] Trial 40 finished with value: 0.8682170542635659 and parameters: {'depth': 10, 'learning_rate': 0.060004221665914265, 'l2_leaf_reg': 7.651669909016194, 'bagging_temperature': 0.26584743779157793, 'random_strength': 2.6096928402844197}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:34,839] Trial 41 finished with value: 0.8643410852713178 and parameters: {'depth': 6, 'learning_rate': 0.05562916011651858, 'l2_leaf_reg': 4.293946897650639, 'bagging_temperature': 0.08491028119384209, 'random_strength': 5.198556495809845}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:38,088] Trial 42 finished with value: 0.8565891472868217 and parameters: {'depth': 6, 'learning_rate': 0.05809345745732076, 'l2_leaf_reg': 5.249527341858981, 'bagging_temperature': 0.1853268944304792, 'random_strength': 5.676547511856794}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:42,694] Trial 43 finished with value: 0.8643410852713178 and parameters: {'depth': 7, 'learning_rate': 0.07958971568823173, 'l2_leaf_reg': 3.6098581075081757, 'bagging_temperature': 0.05224206897938342, 'random_strength': 4.702322669819471}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:47,093] Trial 44 finished with value: 0.8604651162790697 and parameters: {'depth': 7, 'learning_rate': 0.011904262168063728, 'l2_leaf_reg': 5.746492908298765, 'bagging_temperature': 0.12423583751262218, 'random_strength': 3.3857676456644814}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:49,512] Trial 45 finished with value: 0.8643410852713178 and parameters: {'depth': 5, 'learning_rate': 0.0516251821321462, 'l2_leaf_reg': 4.237975546173336, 'bagging_temperature': 0.23383928911543483, 'random_strength': 6.495484185828767}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:55,979] Trial 46 finished with value: 0.8604651162790697 and parameters: {'depth': 8, 'learning_rate': 0.044046080951128073, 'l2_leaf_reg': 2.644192199727598, 'bagging_temperature': 0.03677109903989728, 'random_strength': 8.56501294081515}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:00:58,971] Trial 47 finished with value: 0.8643410852713178 and parameters: {'depth': 6, 'learning_rate': 0.06708152508968933, 'l2_leaf_reg': 3.546372887259975, 'bagging_temperature': 0.7039932813418116, 'random_strength': 9.724126783251846}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:01:01,019] Trial 48 finished with value: 0.8604651162790697 and parameters: {'depth': 4, 'learning_rate': 0.06408255839975566, 'l2_leaf_reg': 4.493892102627502, 'bagging_temperature': 0.4125365466816011, 'random_strength': 7.247088671453879}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:01:04,805] Trial 49 finished with value: 0.8643410852713178 and parameters: {'depth': 5, 'learning_rate': 0.08540987349626009, 'l2_leaf_reg': 4.003429171672669, 'bagging_temperature': 0.29259461961882965, 'random_strength': 9.22948148118724}. Best is trial 13 with value: 0.875968992248062.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Лучшие параметры:\n",
            "{'depth': 8, 'learning_rate': 0.07467512885213419, 'l2_leaf_reg': 4.579248740631226, 'bagging_temperature': 0.22503495936094642, 'random_strength': 8.038749733809894}\n",
            "\n",
            "Лучшая точность: 0.875968992248062\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Создание полиномиальных признаков (квадратичных)"
      ],
      "metadata": {
        "id": "gY_MLTwN5FB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
        "\n",
        "x_train_poly = poly.fit_transform(x_train)\n",
        "x_test_poly = poly.transform(x_test)\n",
        "\n",
        "x_train_poly = np.hstack([x_train, x_train_poly])\n",
        "x_test_poly = np.hstack([x_test, x_test_poly])"
      ],
      "metadata": {
        "id": "8MOP5uTS5M8G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train_poly.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61LeMO-i7Otm",
        "outputId": "f4804934-88b9-4873-94a9-5b8680f39b77"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1030, 168)"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_train_poly_scaled = scaler.fit_transform(x_train_poly)\n",
        "df_test_poly_scaled = scaler.transform(x_test_poly)\n",
        "\n",
        "pca = PCA(n_components=30)\n",
        "df_train_pca = pca.fit_transform(df_train_poly_scaled)\n",
        "df_test_pca = pca.transform(df_test_poly_scaled)\n",
        "\n",
        "df_train_pca = pd.DataFrame(df_train_pca, columns=[f\"PC{i+1}\" for i in range(30)])\n",
        "df_test_pca = pd.DataFrame(df_test_pca, columns=[f\"PC{i+1}\" for i in range(30)])\n",
        "\n",
        "print(df_train_pca.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADEelnx77Yn4",
        "outputId": "b32d13d8-bcfe-4a33-c55b-895232e7452b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         PC1       PC2        PC3       PC4       PC5       PC6       PC7  \\\n",
            "0  12.120131  0.057488 -11.791924 -0.849301 -0.974745 -0.197336  1.739145   \n",
            "1   2.698781 -3.204377 -12.224059  0.530703 -1.719710 -0.137208 -0.042690   \n",
            "2  -0.251102 -9.056472   6.279971 -0.483540 -2.317425  0.812963  0.083169   \n",
            "3  11.566232  1.667467  -7.723755 -0.973811 -1.457143  0.210376  1.037748   \n",
            "4   8.437343  7.523172   2.977514 -1.777060 -0.284277  0.333730  0.656276   \n",
            "\n",
            "        PC8       PC9      PC10  ...      PC21      PC22      PC23      PC24  \\\n",
            "0  0.245132 -0.491380  0.626683  ...  0.022717  0.144169  0.005961 -0.101968   \n",
            "1 -0.624833 -0.663961  0.217494  ... -0.126023  0.017247 -0.010745 -0.022938   \n",
            "2 -0.410632  0.713092 -0.346159  ...  0.132326 -0.033217  0.077995  0.003248   \n",
            "3  0.249467 -0.533763  0.014057  ... -0.003637  0.110582  0.002951 -0.066300   \n",
            "4  0.314635  0.416587  0.471774  ...  0.017707  0.070915  0.016231 -0.002380   \n",
            "\n",
            "       PC25      PC26      PC27      PC28      PC29      PC30  \n",
            "0  0.002407  0.042681 -0.077164  0.000734 -0.029333  0.050554  \n",
            "1  0.012788 -0.017159  0.028538 -0.010069 -0.012143 -0.002888  \n",
            "2  0.000908  0.008862 -0.003684  0.042995 -0.009728 -0.014672  \n",
            "3 -0.003676  0.006192 -0.046845 -0.016689 -0.009326  0.010563  \n",
            "4 -0.007700  0.019876  0.021183  0.013154  0.004975 -0.016970  \n",
            "\n",
            "[5 rows x 30 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=300, max_depth=10, random_state=42)\n",
        "model.fit(df_train_pca, y_train)\n",
        "\n",
        "y_pred = model.predict(df_test_pca)\n",
        "print('Accuracy:', accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72Xv5hn87t7-",
        "outputId": "520033d0-8a32-49e5-c682-b57daf621013"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.8604651162790697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "scaler = StandardScaler()\n",
        "df_train_poly_scaled = scaler.fit_transform(x_train)\n",
        "df_test_poly_scaled = scaler.transform(x_test)\n",
        "\n",
        "pca = PCA()\n",
        "pca.fit(df_train_poly_scaled)\n",
        "\n",
        "explained_variance_ratio = pca.explained_variance_ratio_\n",
        "\n",
        "plt.plot(range(1, len(explained_variance_ratio) + 1), explained_variance_ratio.cumsum(), marker='o', color='b')\n",
        "plt.xlabel('Number of Components')\n",
        "plt.ylabel('Cumulative Explained Variance')\n",
        "plt.title('Explained Variance by Number of Components')\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "n_components = next(i for i, cumsum in enumerate(pca.explained_variance_ratio_.cumsum()) if cumsum >= 0.99) + 1\n",
        "print(f\"Optimal number of components: {n_components}\")\n",
        "\n",
        "pca = PCA(n_components=n_components)\n",
        "df_train_pca = pca.fit_transform(df_train_poly_scaled)\n",
        "df_test_pca = pca.transform(df_test_poly_scaled)\n",
        "\n",
        "df_train_pca = pd.DataFrame(df_train_pca, columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
        "df_test_pca = pd.DataFrame(df_test_pca, columns=[f\"PC{i+1}\" for i in range(n_components)])\n",
        "\n",
        "print(df_train_pca.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 591
        },
        "id": "M_awCEkf7_nW",
        "outputId": "da78e6fb-18a4-44d3-b011-0e2f21eeb6cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimal number of components: 6\n",
            "        PC1       PC2       PC3       PC4       PC5       PC6\n",
            "0 -4.229246 -0.076326 -3.199633 -0.539112 -0.302699  0.195221\n",
            "1 -1.741177 -1.443960 -3.525887 -0.202970 -0.554153 -0.068203\n",
            "2 -0.211487 -2.369800  2.204929 -0.208721 -0.797822  0.321159\n",
            "3 -3.768765  0.553140 -2.051230 -0.584229 -0.387449  0.162942\n",
            "4 -1.891455  2.634643  0.889150 -0.579466  0.021137  0.173937\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import optuna\n",
        "import numpy as np\n",
        "from catboost import CatBoostClassifier, Pool\n",
        "\n",
        "\n",
        "feature_names = X.columns.tolist()\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"iterations\": 10000,\n",
        "        \"early_stopping_rounds\": 100,\n",
        "        \"depth\": trial.suggest_int(\"depth\", 6, 8),\n",
        "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.1),\n",
        "        \"l2_leaf_reg\": trial.suggest_float(\"l2_leaf_reg\", 1, 10),\n",
        "        \"bagging_temperature\": trial.suggest_float(\"bagging_temperature\", 0, 1),\n",
        "        \"random_strength\": trial.suggest_float(\"random_strength\", 1, 10),\n",
        "        \"loss_function\": \"Logloss\",\n",
        "        \"eval_metric\": \"Accuracy\",\n",
        "        \"verbose\": 0,\n",
        "        \"task_type\": \"GPU\",\n",
        "        \"devices\": \"0\"\n",
        "    }\n",
        "\n",
        "    model = CatBoostClassifier(**params)\n",
        "\n",
        "    # Обучаем модель\n",
        "    model.fit(df_train_pca, y_train, eval_set=(df_test_pca, y_test), use_best_model=True)\n",
        "\n",
        "    preds = model.predict(df_test_pca)\n",
        "    accuracy = accuracy_score(y_test, preds)\n",
        "    return accuracy\n",
        "\n",
        "study = optuna.create_study(direction=\"maximize\")\n",
        "study.optimize(objective, n_trials=50)\n",
        "\n",
        "print(\"\\nЛучшие параметры:\")\n",
        "print(study.best_params)\n",
        "print(\"\\nЛучшая точность:\", study.best_value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vvjdyAtJAIBH",
        "outputId": "417c7c38-75cd-4053-c486-883408857961"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-26 21:30:38,875] A new study created in memory with name: no-name-9263240e-0d54-4f15-9668-3a29740897f5\n",
            "[I 2025-04-26 21:30:51,167] Trial 0 finished with value: 0.872093023255814 and parameters: {'depth': 7, 'learning_rate': 0.029983923508322505, 'l2_leaf_reg': 1.8106479075276565, 'bagging_temperature': 0.4982424523369824, 'random_strength': 5.990754742884508}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:30:58,747] Trial 1 finished with value: 0.872093023255814 and parameters: {'depth': 7, 'learning_rate': 0.05863605030135984, 'l2_leaf_reg': 6.790555577458529, 'bagging_temperature': 0.8739208589572349, 'random_strength': 5.136025538804162}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:31:11,955] Trial 2 finished with value: 0.872093023255814 and parameters: {'depth': 7, 'learning_rate': 0.02270994902780389, 'l2_leaf_reg': 3.665654814363666, 'bagging_temperature': 0.6256866251238505, 'random_strength': 3.1682291956711524}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:31:20,168] Trial 3 finished with value: 0.8604651162790697 and parameters: {'depth': 7, 'learning_rate': 0.03051950400836078, 'l2_leaf_reg': 7.080715153349127, 'bagging_temperature': 0.19389740644998377, 'random_strength': 1.3561775373934526}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:31:30,711] Trial 4 finished with value: 0.8682170542635659 and parameters: {'depth': 7, 'learning_rate': 0.027344345415613487, 'l2_leaf_reg': 7.246058267969772, 'bagging_temperature': 0.3563612544908492, 'random_strength': 5.262606518600283}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:31:34,465] Trial 5 finished with value: 0.8643410852713178 and parameters: {'depth': 6, 'learning_rate': 0.0887740265484818, 'l2_leaf_reg': 8.21981078454873, 'bagging_temperature': 0.7930441716840088, 'random_strength': 9.120649607279816}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:31:38,366] Trial 6 finished with value: 0.8527131782945736 and parameters: {'depth': 7, 'learning_rate': 0.012803865379334079, 'l2_leaf_reg': 5.9678271313792175, 'bagging_temperature': 0.23695334405810586, 'random_strength': 6.961017523423942}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:31:52,667] Trial 7 finished with value: 0.8643410852713178 and parameters: {'depth': 8, 'learning_rate': 0.04204607446730099, 'l2_leaf_reg': 5.024873875682258, 'bagging_temperature': 0.4866174956669611, 'random_strength': 6.981950801178392}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:31:59,837] Trial 8 finished with value: 0.8488372093023255 and parameters: {'depth': 8, 'learning_rate': 0.014480059240871972, 'l2_leaf_reg': 7.207538151324734, 'bagging_temperature': 0.7930813588106601, 'random_strength': 4.910865780503775}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:32:07,982] Trial 9 finished with value: 0.8604651162790697 and parameters: {'depth': 7, 'learning_rate': 0.019863578054149483, 'l2_leaf_reg': 9.928096789950269, 'bagging_temperature': 0.7163255337050358, 'random_strength': 8.597756208883}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:32:12,846] Trial 10 finished with value: 0.8643410852713178 and parameters: {'depth': 6, 'learning_rate': 0.06456476322032373, 'l2_leaf_reg': 1.5922460176547388, 'bagging_temperature': 0.002873189621072303, 'random_strength': 3.156024997999207}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:32:30,845] Trial 11 finished with value: 0.872093023255814 and parameters: {'depth': 8, 'learning_rate': 0.062104855650776246, 'l2_leaf_reg': 1.069750211247215, 'bagging_temperature': 0.9750663472023378, 'random_strength': 6.892983842174377}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:32:37,609] Trial 12 finished with value: 0.8682170542635659 and parameters: {'depth': 6, 'learning_rate': 0.049250445890337405, 'l2_leaf_reg': 3.140924660765979, 'bagging_temperature': 0.9898915142932128, 'random_strength': 3.9513107553616234}. Best is trial 0 with value: 0.872093023255814.\n",
            "[I 2025-04-26 21:32:45,614] Trial 13 finished with value: 0.875968992248062 and parameters: {'depth': 7, 'learning_rate': 0.07992148828697894, 'l2_leaf_reg': 4.786262439131312, 'bagging_temperature': 0.539221135315088, 'random_strength': 6.193151615814536}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:32:49,910] Trial 14 finished with value: 0.872093023255814 and parameters: {'depth': 6, 'learning_rate': 0.08976271766315963, 'l2_leaf_reg': 3.0880746534165877, 'bagging_temperature': 0.5134106363312589, 'random_strength': 6.318190759091423}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:33:00,053] Trial 15 finished with value: 0.8682170542635659 and parameters: {'depth': 7, 'learning_rate': 0.07394014353735572, 'l2_leaf_reg': 3.903215880594811, 'bagging_temperature': 0.5142778352872971, 'random_strength': 8.017681877633573}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:33:10,138] Trial 16 finished with value: 0.872093023255814 and parameters: {'depth': 8, 'learning_rate': 0.09902203240707122, 'l2_leaf_reg': 2.2362036807041794, 'bagging_temperature': 0.3701275577206084, 'random_strength': 8.08947173815807}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:33:19,791] Trial 17 finished with value: 0.872093023255814 and parameters: {'depth': 7, 'learning_rate': 0.07547279526364178, 'l2_leaf_reg': 4.984184532062212, 'bagging_temperature': 0.6129290623081848, 'random_strength': 6.049451879753518}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:33:29,191] Trial 18 finished with value: 0.8682170542635659 and parameters: {'depth': 8, 'learning_rate': 0.045616156896365806, 'l2_leaf_reg': 2.231584330401956, 'bagging_temperature': 0.3409744070288837, 'random_strength': 9.635828203193437}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:33:35,530] Trial 19 finished with value: 0.8682170542635659 and parameters: {'depth': 6, 'learning_rate': 0.03478276520701823, 'l2_leaf_reg': 4.294642543967214, 'bagging_temperature': 0.6546402108199387, 'random_strength': 4.122615880817173}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:33:41,043] Trial 20 finished with value: 0.8643410852713178 and parameters: {'depth': 7, 'learning_rate': 0.07457514260247168, 'l2_leaf_reg': 5.883098985705786, 'bagging_temperature': 0.4698582626158844, 'random_strength': 7.450457831072796}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:33:48,583] Trial 21 finished with value: 0.875968992248062 and parameters: {'depth': 7, 'learning_rate': 0.054078592215563284, 'l2_leaf_reg': 8.166233168107379, 'bagging_temperature': 0.8794120089177497, 'random_strength': 5.717637097818653}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:33:57,131] Trial 22 finished with value: 0.8604651162790697 and parameters: {'depth': 7, 'learning_rate': 0.039326932950298446, 'l2_leaf_reg': 9.203842963175529, 'bagging_temperature': 0.11961666323430076, 'random_strength': 5.797296402767463}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:34:05,612] Trial 23 finished with value: 0.872093023255814 and parameters: {'depth': 7, 'learning_rate': 0.055657781726692834, 'l2_leaf_reg': 8.293915781763209, 'bagging_temperature': 0.8905982944811255, 'random_strength': 4.407546241433262}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:34:16,213] Trial 24 finished with value: 0.8682170542635659 and parameters: {'depth': 7, 'learning_rate': 0.06802653032838143, 'l2_leaf_reg': 8.358417570989172, 'bagging_temperature': 0.5810051952437216, 'random_strength': 6.114516157831412}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:34:25,114] Trial 25 finished with value: 0.8682170542635659 and parameters: {'depth': 7, 'learning_rate': 0.049087921475936186, 'l2_leaf_reg': 6.255070672899056, 'bagging_temperature': 0.7471483551436957, 'random_strength': 3.2223195788134706}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:34:34,275] Trial 26 finished with value: 0.8682170542635659 and parameters: {'depth': 8, 'learning_rate': 0.08610578027810975, 'l2_leaf_reg': 4.963915132762276, 'bagging_temperature': 0.4382334006129393, 'random_strength': 1.3016523134019335}. Best is trial 13 with value: 0.875968992248062.\n",
            "[I 2025-04-26 21:34:40,976] Trial 27 finished with value: 0.8798449612403101 and parameters: {'depth': 6, 'learning_rate': 0.08055420581316251, 'l2_leaf_reg': 2.6065991462624782, 'bagging_temperature': 0.6896185789130034, 'random_strength': 6.52346788695443}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:34:46,694] Trial 28 finished with value: 0.8682170542635659 and parameters: {'depth': 6, 'learning_rate': 0.07991408241697211, 'l2_leaf_reg': 3.0694475966758614, 'bagging_temperature': 0.7121568104426462, 'random_strength': 7.712096015307047}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:34:51,803] Trial 29 finished with value: 0.8682170542635659 and parameters: {'depth': 6, 'learning_rate': 0.09964601965619208, 'l2_leaf_reg': 4.422049111845526, 'bagging_temperature': 0.872119130553911, 'random_strength': 6.53460221874073}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:34:57,711] Trial 30 finished with value: 0.8527131782945736 and parameters: {'depth': 6, 'learning_rate': 0.08308120889939877, 'l2_leaf_reg': 7.613982924970534, 'bagging_temperature': 0.8103100262973418, 'random_strength': 5.630304739614965}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:35:03,423] Trial 31 finished with value: 0.8682170542635659 and parameters: {'depth': 7, 'learning_rate': 0.06979593014516684, 'l2_leaf_reg': 2.208225402145316, 'bagging_temperature': 0.5662685150965123, 'random_strength': 4.934700281193019}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:35:09,763] Trial 32 finished with value: 0.8643410852713178 and parameters: {'depth': 7, 'learning_rate': 0.05948722363516651, 'l2_leaf_reg': 1.0221203162473362, 'bagging_temperature': 0.6710264652849178, 'random_strength': 5.383008302077625}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:35:17,543] Trial 33 finished with value: 0.872093023255814 and parameters: {'depth': 7, 'learning_rate': 0.05422044445273745, 'l2_leaf_reg': 1.8452913982080186, 'bagging_temperature': 0.41611435407956215, 'random_strength': 7.390181950372109}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:35:22,362] Trial 34 finished with value: 0.8565891472868217 and parameters: {'depth': 6, 'learning_rate': 0.0948964724725036, 'l2_leaf_reg': 6.5875255190148945, 'bagging_temperature': 0.9095795780825545, 'random_strength': 4.857512391323226}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:35:29,606] Trial 35 finished with value: 0.8604651162790697 and parameters: {'depth': 7, 'learning_rate': 0.029804295427193515, 'l2_leaf_reg': 3.707347899322337, 'bagging_temperature': 0.5576753481338483, 'random_strength': 5.686469240489011}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:35:39,893] Trial 36 finished with value: 0.8643410852713178 and parameters: {'depth': 7, 'learning_rate': 0.0234495893944184, 'l2_leaf_reg': 2.596482105515347, 'bagging_temperature': 0.31291643100558597, 'random_strength': 6.566761550941714}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:35:47,524] Trial 37 finished with value: 0.872093023255814 and parameters: {'depth': 7, 'learning_rate': 0.08127459746659152, 'l2_leaf_reg': 5.489881689821804, 'bagging_temperature': 0.8485589329991075, 'random_strength': 8.568022994155323}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:36:03,254] Trial 38 finished with value: 0.8682170542635659 and parameters: {'depth': 8, 'learning_rate': 0.037077384772887585, 'l2_leaf_reg': 1.5201863659620554, 'bagging_temperature': 0.6330475378736762, 'random_strength': 2.3441533131868075}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:36:10,391] Trial 39 finished with value: 0.875968992248062 and parameters: {'depth': 6, 'learning_rate': 0.06504354465831298, 'l2_leaf_reg': 7.622453437631576, 'bagging_temperature': 0.7399209970891998, 'random_strength': 7.009374442550012}. Best is trial 27 with value: 0.8798449612403101.\n",
            "[I 2025-04-26 21:36:15,216] Trial 40 finished with value: 0.8837209302325582 and parameters: {'depth': 6, 'learning_rate': 0.06833784255065162, 'l2_leaf_reg': 8.908196106014795, 'bagging_temperature': 0.7477685179197879, 'random_strength': 7.032204265665096}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:36:19,212] Trial 41 finished with value: 0.872093023255814 and parameters: {'depth': 6, 'learning_rate': 0.06822181875355351, 'l2_leaf_reg': 9.18260115680773, 'bagging_temperature': 0.778205187370901, 'random_strength': 7.089510034221637}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:36:24,501] Trial 42 finished with value: 0.8682170542635659 and parameters: {'depth': 6, 'learning_rate': 0.07702388232744711, 'l2_leaf_reg': 7.706051294047889, 'bagging_temperature': 0.7508848631296315, 'random_strength': 6.556761252666473}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:36:29,712] Trial 43 finished with value: 0.872093023255814 and parameters: {'depth': 6, 'learning_rate': 0.06525925021895945, 'l2_leaf_reg': 8.999031375469821, 'bagging_temperature': 0.9314099933125012, 'random_strength': 7.165995643823813}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:36:34,154] Trial 44 finished with value: 0.872093023255814 and parameters: {'depth': 6, 'learning_rate': 0.07067585482838976, 'l2_leaf_reg': 8.650645386958823, 'bagging_temperature': 0.6875882399006168, 'random_strength': 7.804219330369776}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:36:40,372] Trial 45 finished with value: 0.872093023255814 and parameters: {'depth': 6, 'learning_rate': 0.05687419539320598, 'l2_leaf_reg': 9.81579343946952, 'bagging_temperature': 0.8230728248090888, 'random_strength': 8.46368308214436}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:36:45,043] Trial 46 finished with value: 0.8682170542635659 and parameters: {'depth': 6, 'learning_rate': 0.06369104836663207, 'l2_leaf_reg': 6.921410747723966, 'bagging_temperature': 0.7402069299873587, 'random_strength': 6.85376303040368}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:36:50,900] Trial 47 finished with value: 0.875968992248062 and parameters: {'depth': 6, 'learning_rate': 0.05161371349446765, 'l2_leaf_reg': 7.599117559397454, 'bagging_temperature': 0.8474270641988406, 'random_strength': 5.310391679852039}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:36:56,473] Trial 48 finished with value: 0.872093023255814 and parameters: {'depth': 6, 'learning_rate': 0.0885291277962532, 'l2_leaf_reg': 7.884792758287602, 'bagging_temperature': 0.6945957962909837, 'random_strength': 6.183320681998749}. Best is trial 40 with value: 0.8837209302325582.\n",
            "[I 2025-04-26 21:37:03,530] Trial 49 finished with value: 0.8682170542635659 and parameters: {'depth': 6, 'learning_rate': 0.0920855534917931, 'l2_leaf_reg': 8.642551157144554, 'bagging_temperature': 0.9302489162661981, 'random_strength': 9.221505486033452}. Best is trial 40 with value: 0.8837209302325582.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Лучшие параметры:\n",
            "{'depth': 6, 'learning_rate': 0.06833784255065162, 'l2_leaf_reg': 8.908196106014795, 'bagging_temperature': 0.7477685179197879, 'random_strength': 7.032204265665096}\n",
            "\n",
            "Лучшая точность: 0.8837209302325582\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ансамбль моделей (CatBoost, XGBoost, LightGBM) с помощью VotingClassifier"
      ],
      "metadata": {
        "id": "B-4LkYC7TxbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = df_train.drop(columns=['target'])\n",
        "y_train = df_train['target']\n",
        "X_test = df_test.copy()\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# 3. Генерация полиномиальных признаков степени 2 (PolynomialFeatures)\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=False, include_bias=False)\n",
        "X_train_poly = poly.fit_transform(X_train_scaled)\n",
        "X_test_poly = poly.transform(X_test_scaled)\n",
        "# Получаем имена новых признаков (для понимания структуры данных)\n",
        "feature_names = poly.get_feature_names_out(input_features=X_train.columns)\n",
        "X_train_poly_df = pd.DataFrame(X_train_poly, columns=feature_names)\n",
        "X_test_poly_df = pd.DataFrame(X_test_poly, columns=feature_names)\n",
        "\n",
        "# 4. Фильтрация признаков (удаление высоко коррелированных)\n",
        "# Вычисляем корреляционную матрицу по абсолютным значениям\n",
        "corr_matrix = X_train_poly_df.corr().abs()\n",
        "# Извлекаем верхний треугольник корреляционной матрицы (без диагонали)\n",
        "upper_tri = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
        "# Определяем признаки с корреляцией выше пороговой (например, 0.95) и удаляем их\n",
        "threshold = 0.95\n",
        "to_drop = [col for col in upper_tri.columns if any(upper_tri[col] > threshold)]\n",
        "X_train_poly_df_reduced = X_train_poly_df.drop(columns=to_drop)\n",
        "X_test_poly_df_reduced = X_test_poly_df.drop(columns=to_drop)\n",
        "print(f\"Удалено {len(to_drop)} высоко коррелированных признаков из полиномиальных данных.\")\n",
        "\n",
        "# 5. Уменьшение размерности через PCA (сохранение 99% дисперсии)\n",
        "from sklearn.decomposition import PCA\n",
        "pca = PCA(n_components=0.99, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_poly_df_reduced)\n",
        "X_test_pca = pca.transform(X_test_poly_df_reduced)\n",
        "print(f\"PCA завершен. Количество компонент после снижения размерности: {X_train_pca.shape[1]}\")\n",
        "\n",
        "# 6. Подбор гиперпараметров для CatBoostClassifier через Optuna (используем CPU или GPU)\n",
        "import optuna\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "def objective(trial):\n",
        "    params = {\n",
        "        \"iterations\": 1000,\n",
        "        \"early_stopping_rounds\": 100,\n",
        "        'learning_rate': trial.suggest_float('learning_rate', 1e-3, 1e-1),\n",
        "        'depth': trial.suggest_int('depth', 6, 8),\n",
        "        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 5, 10),\n",
        "        'bagging_temperature': trial.suggest_float('bagging_temperature', 0.1, 1.0),\n",
        "        'random_strength': trial.suggest_int('random_strength', 1, 10),\n",
        "        # Используем GPU, если доступно; иначе CPU (требуется собрать перед этим информацию о наличии GPU)\n",
        "        'task_type': 'CPU'\n",
        "    }\n",
        "    model = CatBoostClassifier(**params, eval_metric='Accuracy', verbose=False)\n",
        "    # Кросс-валидация по 3 фолдам, метрика accuracy\n",
        "    scores = cross_val_score(model, X_train_pca, y_train, cv=3, scoring='accuracy')\n",
        "    return scores.mean()\n",
        "\n",
        "study = optuna.create_study(direction='maximize')\n",
        "study.optimize(objective, n_trials=20)\n",
        "best_params = study.best_params\n",
        "print(\"Лучшие параметры CatBoost:\", best_params)\n",
        "\n",
        "# Обучение CatBoost с лучшими гиперпараметрами на всем тренировочном наборе\n",
        "best_catboost = CatBoostClassifier(**best_params, eval_metric='Accuracy', verbose=50, early_stopping_rounds=20)\n",
        "best_catboost.fit(X_train_pca, y_train)\n",
        "print(\"CatBoost обучен с оптимальными гиперпараметрами.\")\n",
        "\n",
        "# 7. Псевдоразметка: предсказания на тестовом наборе и отбор уверенных предсказаний\n",
        "probs = best_catboost.predict_proba(X_test_pca)\n",
        "# Берем те объекты, для которых максимальная вероятность > threshold\n",
        "threshold_pl = 0.9\n",
        "pseudo_idxs = np.where(probs.max(axis=1) >= threshold_pl)[0]\n",
        "pseudo_labels = np.argmax(probs[pseudo_idxs], axis=1)\n",
        "print(f\"Найдено {len(pseudo_idxs)} уверенных предсказаний для псевдоразметки.\")\n",
        "\n",
        "# Добавляем псевдоразмеченные данные к обучающему набору\n",
        "X_train_extended = np.vstack([X_train_pca, X_test_pca[pseudo_idxs]])\n",
        "y_train_extended = np.concatenate([y_train, pseudo_labels])\n",
        "print(f\"Размер расширенного обучающего набора: {X_train_extended.shape[0]} объектов.\")\n",
        "\n",
        "# 8. Построение ансамбля моделей (CatBoost, XGBoost, LightGBM) через VotingClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from lightgbm import LGBMClassifier\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "cat_model = CatBoostClassifier(**best_params, eval_metric='Accuracy', verbose=False)\n",
        "xgb_model = XGBClassifier(use_label_encoder=False, eval_metric='logloss', verbosity=0)\n",
        "lgb_model = LGBMClassifier()\n",
        "\n",
        "ensemble = VotingClassifier(\n",
        "    estimators=[\n",
        "        ('cat', cat_model),\n",
        "        ('xgb', xgb_model),\n",
        "        ('lgb', lgb_model)\n",
        "    ],\n",
        "    voting='soft'\n",
        ")\n",
        "print(\"Ансамбль моделей создан (CatBoost, XGBoost, LightGBM).\")\n",
        "\n",
        "# 9. Обучение ансамбля на расширенном датасете\n",
        "ensemble.fit(X_train_extended, y_train_extended)\n",
        "print(\"Ансамбль моделей обучен на расширенных данных.\")\n",
        "\n",
        "# 10. Оценка финальной модели (здесь используем кросс-валидацию на расширенных данных)\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "scores = cross_val_score(ensemble, X_train_extended, y_train_extended, cv=3, scoring='accuracy')\n",
        "print(f\"Точность ансамбля (3-fold CV): {scores.mean():.4f} ± {scores.std():.4f}\")\n",
        "\n",
        "# (Дополнительно можно оценить на отложенной части, если есть разделение на валидацию)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VwikwAaQAzzQ",
        "outputId": "b9321e1b-810a-4784-d457-3b9d9e572be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-26 21:43:18,382] A new study created in memory with name: no-name-0a1b67c8-5210-4d25-a493-d7cd1f74c2d5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Удалено 50 высоко коррелированных признаков из полиномиальных данных.\n",
            "PCA завершен. Количество компонент после снижения размерности: 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[I 2025-04-26 21:43:45,821] Trial 0 finished with value: 0.8586924703203773 and parameters: {'learning_rate': 0.039884134268652005, 'depth': 7, 'l2_leaf_reg': 9.35914266777634, 'bagging_temperature': 0.35436683303718075, 'random_strength': 3}. Best is trial 0 with value: 0.8586924703203773.\n",
            "[I 2025-04-26 21:44:13,608] Trial 1 finished with value: 0.8610216656728285 and parameters: {'learning_rate': 0.0433435459145185, 'depth': 7, 'l2_leaf_reg': 9.26091855421324, 'bagging_temperature': 0.5399810995022253, 'random_strength': 1}. Best is trial 1 with value: 0.8610216656728285.\n",
            "[I 2025-04-26 21:44:30,017] Trial 2 finished with value: 0.8618022804069315 and parameters: {'learning_rate': 0.04371562997365058, 'depth': 6, 'l2_leaf_reg': 6.904560768167939, 'bagging_temperature': 0.1483884472829873, 'random_strength': 3}. Best is trial 2 with value: 0.8618022804069315.\n",
            "[I 2025-04-26 21:44:58,635] Trial 3 finished with value: 0.8656836703348331 and parameters: {'learning_rate': 0.012088895824309675, 'depth': 7, 'l2_leaf_reg': 8.457586942153373, 'bagging_temperature': 0.5964739814005962, 'random_strength': 7}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:45:26,005] Trial 4 finished with value: 0.8617968594712782 and parameters: {'learning_rate': 0.057283297221962404, 'depth': 7, 'l2_leaf_reg': 8.363944681694903, 'bagging_temperature': 0.5942074660990481, 'random_strength': 4}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:46:16,441] Trial 5 finished with value: 0.8602446648958276 and parameters: {'learning_rate': 0.044048542258593136, 'depth': 8, 'l2_leaf_reg': 8.075311117327901, 'bagging_temperature': 0.8335294900050906, 'random_strength': 6}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:46:32,741] Trial 6 finished with value: 0.8602446648958276 and parameters: {'learning_rate': 0.09521167475122139, 'depth': 6, 'l2_leaf_reg': 7.512350055229021, 'bagging_temperature': 0.9695436980630164, 'random_strength': 3}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:46:50,348] Trial 7 finished with value: 0.8641296687808314 and parameters: {'learning_rate': 0.00828026930611872, 'depth': 6, 'l2_leaf_reg': 8.037049006662807, 'bagging_temperature': 0.3103748760102605, 'random_strength': 8}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:47:06,684] Trial 8 finished with value: 0.8586906633418261 and parameters: {'learning_rate': 0.04274426323401282, 'depth': 6, 'l2_leaf_reg': 5.515897525600836, 'bagging_temperature': 0.12121447752931938, 'random_strength': 8}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:47:34,564] Trial 9 finished with value: 0.8532498509242695 and parameters: {'learning_rate': 0.0991216786158388, 'depth': 7, 'l2_leaf_reg': 6.7758496831248385, 'bagging_temperature': 0.7360134926833227, 'random_strength': 7}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:48:24,777] Trial 10 finished with value: 0.8555935021051301 and parameters: {'learning_rate': 0.0015015916966324757, 'depth': 8, 'l2_leaf_reg': 5.3459046154469565, 'bagging_temperature': 0.5414182262884373, 'random_strength': 10}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:48:42,015] Trial 11 finished with value: 0.8555880811694765 and parameters: {'learning_rate': 0.0021913120233413887, 'depth': 6, 'l2_leaf_reg': 8.55798962422486, 'bagging_temperature': 0.3416912946479401, 'random_strength': 9}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:49:33,678] Trial 12 finished with value: 0.8633526680038308 and parameters: {'learning_rate': 0.01979599894651371, 'depth': 8, 'l2_leaf_reg': 9.806554621821078, 'bagging_temperature': 0.32512305542898184, 'random_strength': 7}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:49:49,885] Trial 13 finished with value: 0.8633490540467283 and parameters: {'learning_rate': 0.017131117878754196, 'depth': 6, 'l2_leaf_reg': 7.049991169795662, 'bagging_temperature': 0.4476666051282096, 'random_strength': 5}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:50:18,661] Trial 14 finished with value: 0.8602410509387254 and parameters: {'learning_rate': 0.022491465428986696, 'depth': 7, 'l2_leaf_reg': 7.6754162917108975, 'bagging_temperature': 0.6720230031349632, 'random_strength': 9}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:50:46,233] Trial 15 finished with value: 0.8586834354276215 and parameters: {'learning_rate': 0.07864124484160409, 'depth': 7, 'l2_leaf_reg': 6.18506161920504, 'bagging_temperature': 0.23450197925143995, 'random_strength': 7}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:51:02,283] Trial 16 finished with value: 0.8548074664353734 and parameters: {'learning_rate': 0.025805590900835174, 'depth': 6, 'l2_leaf_reg': 8.797914391453006, 'bagging_temperature': 0.4503864260822345, 'random_strength': 10}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:51:53,113] Trial 17 finished with value: 0.8649048625792813 and parameters: {'learning_rate': 0.012812336060634574, 'depth': 8, 'l2_leaf_reg': 7.86383392409822, 'bagging_temperature': 0.8107947240816172, 'random_strength': 6}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:52:42,673] Trial 18 finished with value: 0.8625702462911765 and parameters: {'learning_rate': 0.06101499289973615, 'depth': 8, 'l2_leaf_reg': 8.994036901429249, 'bagging_temperature': 0.8579590336177124, 'random_strength': 5}. Best is trial 3 with value: 0.8656836703348331.\n",
            "[I 2025-04-26 21:53:31,884] Trial 19 finished with value: 0.8610198586942773 and parameters: {'learning_rate': 0.03164589270861698, 'depth': 8, 'l2_leaf_reg': 6.231402893874141, 'bagging_temperature': 0.7590386073224099, 'random_strength': 6}. Best is trial 3 with value: 0.8656836703348331.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Лучшие параметры CatBoost: {'learning_rate': 0.012088895824309675, 'depth': 7, 'l2_leaf_reg': 8.457586942153373, 'bagging_temperature': 0.5964739814005962, 'random_strength': 7}\n",
            "0:\tlearn: 0.7849379\ttotal: 10.3ms\tremaining: 10.2s\n",
            "50:\tlearn: 0.8687888\ttotal: 436ms\tremaining: 8.12s\n",
            "100:\tlearn: 0.8796584\ttotal: 851ms\tremaining: 7.57s\n",
            "150:\tlearn: 0.8819876\ttotal: 1.29s\tremaining: 7.25s\n",
            "200:\tlearn: 0.8920807\ttotal: 1.91s\tremaining: 7.6s\n",
            "250:\tlearn: 0.8982919\ttotal: 2.93s\tremaining: 8.74s\n",
            "300:\tlearn: 0.9021739\ttotal: 3.87s\tremaining: 8.99s\n",
            "350:\tlearn: 0.9076087\ttotal: 4.3s\tremaining: 7.94s\n",
            "400:\tlearn: 0.9114907\ttotal: 4.72s\tremaining: 7.04s\n",
            "450:\tlearn: 0.9153727\ttotal: 5.13s\tremaining: 6.25s\n",
            "500:\tlearn: 0.9192547\ttotal: 5.57s\tremaining: 5.55s\n",
            "550:\tlearn: 0.9239130\ttotal: 6s\tremaining: 4.89s\n",
            "600:\tlearn: 0.9262422\ttotal: 6.43s\tremaining: 4.27s\n",
            "650:\tlearn: 0.9316770\ttotal: 6.84s\tremaining: 3.67s\n",
            "700:\tlearn: 0.9378882\ttotal: 7.27s\tremaining: 3.1s\n",
            "750:\tlearn: 0.9433230\ttotal: 7.72s\tremaining: 2.56s\n",
            "800:\tlearn: 0.9487578\ttotal: 8.14s\tremaining: 2.02s\n",
            "850:\tlearn: 0.9526398\ttotal: 8.57s\tremaining: 1.5s\n",
            "900:\tlearn: 0.9596273\ttotal: 8.99s\tremaining: 988ms\n",
            "950:\tlearn: 0.9635093\ttotal: 9.43s\tremaining: 486ms\n",
            "999:\tlearn: 0.9697205\ttotal: 9.83s\tremaining: 0us\n",
            "CatBoost обучен с оптимальными гиперпараметрами.\n",
            "Найдено 264 уверенных предсказаний для псевдоразметки.\n",
            "Размер расширенного обучающего набора: 1552 объектов.\n",
            "Ансамбль моделей создан (CatBoost, XGBoost, LightGBM).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 912, number of negative: 640\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000638 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5610\n",
            "[LightGBM] [Info] Number of data points in the train set: 1552, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.587629 -> initscore=0.354172\n",
            "[LightGBM] [Info] Start training from score 0.354172\n",
            "Ансамбль моделей обучен на расширенных данных.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 608, number of negative: 426\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000323 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5610\n",
            "[LightGBM] [Info] Number of data points in the train set: 1034, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.588008 -> initscore=0.355736\n",
            "[LightGBM] [Info] Start training from score 0.355736\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 608, number of negative: 427\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000329 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5610\n",
            "[LightGBM] [Info] Number of data points in the train set: 1035, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.587440 -> initscore=0.353391\n",
            "[LightGBM] [Info] Start training from score 0.353391\n",
            "[LightGBM] [Warning] No further splits with positive gain, best gain: -inf\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Info] Number of positive: 608, number of negative: 427\n",
            "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000331 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 5610\n",
            "[LightGBM] [Info] Number of data points in the train set: 1035, number of used features: 22\n",
            "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.587440 -> initscore=0.353391\n",
            "[LightGBM] [Info] Start training from score 0.353391\n",
            "Точность ансамбля (3-fold CV): 0.8827 ± 0.0228\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Добавляем нейросети"
      ],
      "metadata": {
        "id": "2OOeNEY1UZcy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(x_train)\n",
        "X_test = scaler.transform(x_test)\n",
        "\n",
        "# Строим более сложную модель нейронной сети\n",
        "model = Sequential()\n",
        "model.add(Input(shape=(X_train.shape[1],)))\n",
        "\n",
        "# Первый скрытый слой\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(BatchNormalization())  # Нормализация после первого слоя\n",
        "model.add(Dropout(0.3))  # Dropout для предотвращения переобучения\n",
        "\n",
        "# Второй скрытый слой\n",
        "model.add(Dense(64, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Третий скрытый слой\n",
        "model.add(Dense(32, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Четвертый скрытый слой\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.3))\n",
        "\n",
        "# Выходной слой\n",
        "model.add(Dense(1))  # Для задачи регрессии (можно поменять активацию для классификации)\n",
        "\n",
        "# Компиляция модели\n",
        "model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Обучаем модель\n",
        "history = model.fit(x_train, y_train, epochs=100, batch_size=64, validation_data=(x_test, y_test), verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rynmk8_PGhsU",
        "outputId": "2c575722-87d2-4469-a74d-a77f935b05b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 208ms/step - accuracy: 0.4434 - loss: 6.6723 - val_accuracy: 0.4496 - val_loss: 8.8712\n",
            "Epoch 2/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 7ms/step - accuracy: 0.5170 - loss: 5.6430 - val_accuracy: 0.4496 - val_loss: 8.8712\n",
            "Epoch 3/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.5072 - loss: 5.0480 - val_accuracy: 0.4496 - val_loss: 8.8712\n",
            "Epoch 4/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6013 - loss: 4.5385 - val_accuracy: 0.4496 - val_loss: 8.7599\n",
            "Epoch 5/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.5811 - loss: 4.5651 - val_accuracy: 0.4496 - val_loss: 8.5842\n",
            "Epoch 6/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6042 - loss: 4.3562 - val_accuracy: 0.4690 - val_loss: 7.9944\n",
            "Epoch 7/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6448 - loss: 4.4290 - val_accuracy: 0.4922 - val_loss: 7.7421\n",
            "Epoch 8/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6379 - loss: 4.2355 - val_accuracy: 0.4961 - val_loss: 7.2940\n",
            "Epoch 9/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6648 - loss: 3.8948 - val_accuracy: 0.5310 - val_loss: 6.3519\n",
            "Epoch 10/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.6455 - loss: 3.8353 - val_accuracy: 0.5194 - val_loss: 6.5154\n",
            "Epoch 11/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6850 - loss: 3.1958 - val_accuracy: 0.5426 - val_loss: 6.1272\n",
            "Epoch 12/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6902 - loss: 3.4787 - val_accuracy: 0.6318 - val_loss: 5.0725\n",
            "Epoch 13/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6845 - loss: 3.3637 - val_accuracy: 0.7326 - val_loss: 3.0281\n",
            "Epoch 14/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6615 - loss: 3.6288 - val_accuracy: 0.8023 - val_loss: 1.9488\n",
            "Epoch 15/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6987 - loss: 3.2681 - val_accuracy: 0.7209 - val_loss: 2.6101\n",
            "Epoch 16/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6497 - loss: 3.7446 - val_accuracy: 0.6628 - val_loss: 4.6775\n",
            "Epoch 17/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7166 - loss: 3.1636 - val_accuracy: 0.6434 - val_loss: 5.1485\n",
            "Epoch 18/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7100 - loss: 3.1538 - val_accuracy: 0.6550 - val_loss: 4.2795\n",
            "Epoch 19/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7329 - loss: 3.1929 - val_accuracy: 0.7093 - val_loss: 3.8096\n",
            "Epoch 20/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7118 - loss: 3.1494 - val_accuracy: 0.7519 - val_loss: 2.6547\n",
            "Epoch 21/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7337 - loss: 3.0198 - val_accuracy: 0.7907 - val_loss: 2.2715\n",
            "Epoch 22/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6965 - loss: 3.5846 - val_accuracy: 0.8178 - val_loss: 2.1132\n",
            "Epoch 23/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7119 - loss: 3.1671 - val_accuracy: 0.8140 - val_loss: 2.0567\n",
            "Epoch 24/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6643 - loss: 3.7589 - val_accuracy: 0.8217 - val_loss: 2.0653\n",
            "Epoch 25/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7145 - loss: 2.9411 - val_accuracy: 0.8178 - val_loss: 2.1871\n",
            "Epoch 26/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7289 - loss: 3.1883 - val_accuracy: 0.8140 - val_loss: 2.2957\n",
            "Epoch 27/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6915 - loss: 3.1576 - val_accuracy: 0.8178 - val_loss: 2.4088\n",
            "Epoch 28/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7242 - loss: 3.3116 - val_accuracy: 0.8101 - val_loss: 2.4580\n",
            "Epoch 29/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7197 - loss: 3.2200 - val_accuracy: 0.7829 - val_loss: 2.4340\n",
            "Epoch 30/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7101 - loss: 3.2052 - val_accuracy: 0.7946 - val_loss: 2.4505\n",
            "Epoch 31/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6821 - loss: 3.5985 - val_accuracy: 0.8140 - val_loss: 2.5089\n",
            "Epoch 32/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7082 - loss: 3.3858 - val_accuracy: 0.7984 - val_loss: 2.3616\n",
            "Epoch 33/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7178 - loss: 3.2899 - val_accuracy: 0.8140 - val_loss: 2.3620\n",
            "Epoch 34/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7286 - loss: 3.2610 - val_accuracy: 0.8101 - val_loss: 2.3573\n",
            "Epoch 35/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7080 - loss: 3.4580 - val_accuracy: 0.8062 - val_loss: 2.4118\n",
            "Epoch 36/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7169 - loss: 3.3637 - val_accuracy: 0.8023 - val_loss: 2.4650\n",
            "Epoch 37/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6955 - loss: 3.2294 - val_accuracy: 0.7984 - val_loss: 2.4228\n",
            "Epoch 38/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7226 - loss: 3.0180 - val_accuracy: 0.7984 - val_loss: 2.4224\n",
            "Epoch 39/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7545 - loss: 2.7951 - val_accuracy: 0.7946 - val_loss: 2.4247\n",
            "Epoch 40/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7067 - loss: 3.2318 - val_accuracy: 0.7946 - val_loss: 2.4227\n",
            "Epoch 41/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7191 - loss: 3.2295 - val_accuracy: 0.8140 - val_loss: 2.3531\n",
            "Epoch 42/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7191 - loss: 3.0792 - val_accuracy: 0.8101 - val_loss: 2.3448\n",
            "Epoch 43/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7338 - loss: 2.7744 - val_accuracy: 0.8140 - val_loss: 2.2970\n",
            "Epoch 44/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7314 - loss: 3.0991 - val_accuracy: 0.8140 - val_loss: 2.2345\n",
            "Epoch 45/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6987 - loss: 3.4766 - val_accuracy: 0.7984 - val_loss: 2.2460\n",
            "Epoch 46/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7284 - loss: 2.9087 - val_accuracy: 0.7907 - val_loss: 2.1091\n",
            "Epoch 47/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7015 - loss: 3.1733 - val_accuracy: 0.7946 - val_loss: 2.0937\n",
            "Epoch 48/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7121 - loss: 2.8601 - val_accuracy: 0.7868 - val_loss: 1.8908\n",
            "Epoch 49/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7091 - loss: 2.9143 - val_accuracy: 0.7829 - val_loss: 1.9022\n",
            "Epoch 50/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7069 - loss: 2.9390 - val_accuracy: 0.7829 - val_loss: 2.0487\n",
            "Epoch 51/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7100 - loss: 3.2409 - val_accuracy: 0.8023 - val_loss: 2.1752\n",
            "Epoch 52/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6775 - loss: 3.3214 - val_accuracy: 0.7636 - val_loss: 2.3210\n",
            "Epoch 53/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6790 - loss: 3.2700 - val_accuracy: 0.7674 - val_loss: 2.2440\n",
            "Epoch 54/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6709 - loss: 3.4792 - val_accuracy: 0.7868 - val_loss: 2.0492\n",
            "Epoch 55/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6825 - loss: 3.4342 - val_accuracy: 0.7791 - val_loss: 1.8785\n",
            "Epoch 56/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6815 - loss: 3.2931 - val_accuracy: 0.8023 - val_loss: 1.7024\n",
            "Epoch 57/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6717 - loss: 3.4456 - val_accuracy: 0.8023 - val_loss: 1.7608\n",
            "Epoch 58/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6994 - loss: 3.1878 - val_accuracy: 0.8062 - val_loss: 2.0659\n",
            "Epoch 59/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6863 - loss: 3.3043 - val_accuracy: 0.7984 - val_loss: 2.0382\n",
            "Epoch 60/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6909 - loss: 3.0950 - val_accuracy: 0.7868 - val_loss: 2.0416\n",
            "Epoch 61/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.6990 - loss: 3.1280 - val_accuracy: 0.7829 - val_loss: 1.9546\n",
            "Epoch 62/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7092 - loss: 3.0729 - val_accuracy: 0.7752 - val_loss: 1.8401\n",
            "Epoch 63/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6914 - loss: 2.6687 - val_accuracy: 0.7829 - val_loss: 1.6507\n",
            "Epoch 64/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7028 - loss: 3.4445 - val_accuracy: 0.7752 - val_loss: 1.6995\n",
            "Epoch 65/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6655 - loss: 3.4378 - val_accuracy: 0.7868 - val_loss: 1.7026\n",
            "Epoch 66/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7042 - loss: 2.9298 - val_accuracy: 0.7868 - val_loss: 1.4100\n",
            "Epoch 67/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6948 - loss: 3.3242 - val_accuracy: 0.7403 - val_loss: 1.6231\n",
            "Epoch 68/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6776 - loss: 3.4967 - val_accuracy: 0.6977 - val_loss: 3.1515\n",
            "Epoch 69/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6925 - loss: 3.4901 - val_accuracy: 0.7326 - val_loss: 2.8021\n",
            "Epoch 70/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7127 - loss: 3.1669 - val_accuracy: 0.7597 - val_loss: 2.5214\n",
            "Epoch 71/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7175 - loss: 3.3482 - val_accuracy: 0.7946 - val_loss: 2.3234\n",
            "Epoch 72/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7437 - loss: 2.7569 - val_accuracy: 0.7984 - val_loss: 2.2982\n",
            "Epoch 73/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7015 - loss: 3.3379 - val_accuracy: 0.8217 - val_loss: 2.3205\n",
            "Epoch 74/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7291 - loss: 3.1176 - val_accuracy: 0.8101 - val_loss: 2.2874\n",
            "Epoch 75/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7082 - loss: 3.4248 - val_accuracy: 0.7984 - val_loss: 2.2478\n",
            "Epoch 76/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7260 - loss: 3.0368 - val_accuracy: 0.7946 - val_loss: 2.1602\n",
            "Epoch 77/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7343 - loss: 3.0577 - val_accuracy: 0.7791 - val_loss: 2.2306\n",
            "Epoch 78/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.6983 - loss: 3.4924 - val_accuracy: 0.7829 - val_loss: 2.3479\n",
            "Epoch 79/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7143 - loss: 3.2292 - val_accuracy: 0.7752 - val_loss: 2.5218\n",
            "Epoch 80/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7024 - loss: 3.2883 - val_accuracy: 0.7713 - val_loss: 2.6689\n",
            "Epoch 81/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7175 - loss: 3.3295 - val_accuracy: 0.7791 - val_loss: 2.6794\n",
            "Epoch 82/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7310 - loss: 2.8982 - val_accuracy: 0.7752 - val_loss: 2.7193\n",
            "Epoch 83/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7162 - loss: 3.2043 - val_accuracy: 0.7674 - val_loss: 2.8366\n",
            "Epoch 84/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6998 - loss: 3.0781 - val_accuracy: 0.7791 - val_loss: 2.6898\n",
            "Epoch 85/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6956 - loss: 2.9423 - val_accuracy: 0.7752 - val_loss: 2.7403\n",
            "Epoch 86/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7126 - loss: 3.1388 - val_accuracy: 0.7752 - val_loss: 2.5071\n",
            "Epoch 87/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.7347 - loss: 2.7997 - val_accuracy: 0.7752 - val_loss: 2.8574\n",
            "Epoch 88/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7366 - loss: 2.8595 - val_accuracy: 0.7481 - val_loss: 2.8888\n",
            "Epoch 89/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.6919 - loss: 3.3170 - val_accuracy: 0.7519 - val_loss: 2.9439\n",
            "Epoch 90/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6980 - loss: 3.0757 - val_accuracy: 0.7868 - val_loss: 1.9913\n",
            "Epoch 91/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7039 - loss: 3.2425 - val_accuracy: 0.7791 - val_loss: 1.9949\n",
            "Epoch 92/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.6969 - loss: 3.5125 - val_accuracy: 0.7597 - val_loss: 1.9352\n",
            "Epoch 93/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7142 - loss: 3.3750 - val_accuracy: 0.7597 - val_loss: 2.1567\n",
            "Epoch 94/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7203 - loss: 3.1111 - val_accuracy: 0.7636 - val_loss: 2.3949\n",
            "Epoch 95/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7315 - loss: 2.7904 - val_accuracy: 0.7636 - val_loss: 2.5651\n",
            "Epoch 96/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7270 - loss: 3.1862 - val_accuracy: 0.7636 - val_loss: 2.6505\n",
            "Epoch 97/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7137 - loss: 2.8919 - val_accuracy: 0.7636 - val_loss: 2.6025\n",
            "Epoch 98/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.7343 - loss: 2.8040 - val_accuracy: 0.7636 - val_loss: 2.6694\n",
            "Epoch 99/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.7155 - loss: 3.2061 - val_accuracy: 0.7597 - val_loss: 2.8166\n",
            "Epoch 100/100\n",
            "\u001b[1m17/17\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.7037 - loss: 3.2119 - val_accuracy: 0.7597 - val_loss: 2.9299\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Модель Gated Mixture of Experts (GG-MoE)"
      ],
      "metadata": {
        "id": "fB3fcBaEUzuW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(x_train)\n",
        "X_test_scaled  = scaler.transform(x_test)\n",
        "\n",
        "pca = PCA(n_components=0.99, random_state=42)\n",
        "X_train_pca = pca.fit_transform(X_train_scaled)\n",
        "X_test_pca  = pca.transform(X_test_scaled)\n"
      ],
      "metadata": {
        "id": "X90gBEnTJcz6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_pca.shape"
      ],
      "metadata": {
        "id": "fKbz8eo3PAfr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Lambda, BatchNormalization, ReLU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "\n",
        "def build_gg_moe(input_dim,\n",
        "                 n_experts=8,\n",
        "                 expert_units=[128, 64],\n",
        "                 gate_units=32,\n",
        "                 dropout_rate=0.2,\n",
        "                 l2_reg=1e-4):\n",
        "    x = Input(shape=(input_dim,), name=\"input\")\n",
        "\n",
        "    # Gating network с BatchNorm + L2\n",
        "    gate = Dense(gate_units, activation=None,\n",
        "                 kernel_regularizer=l2(l2_reg), name=\"gate_dense\")(x)\n",
        "    gate = BatchNormalization(name=\"gate_bn\")(gate)\n",
        "    gate = ReLU()(gate)  # Используем слой ReLU здесь\n",
        "    logits = Dense(n_experts, kernel_regularizer=l2(l2_reg), name=\"gate_logits\")(gate)\n",
        "    gate_weights = Lambda(lambda t: tf.nn.softmax(t, axis=-1), name=\"gate_softmax\")(logits)\n",
        "\n",
        "    # Эксперты: каждый эксперт — MLP с BatchNorm, Dropout и L2\n",
        "    expert_outputs = []\n",
        "    for i in range(n_experts):\n",
        "        h = Dense(expert_units[0], activation=None,\n",
        "                  kernel_regularizer=l2(l2_reg), name=f\"exp{i}_d1\")(x)\n",
        "        h = BatchNormalization(name=f\"exp{i}_bn1\")(h)\n",
        "        h = ReLU()(h)  # Используем слой ReLU здесь\n",
        "        h = Dropout(dropout_rate, name=f\"exp{i}_do1\")(h)\n",
        "\n",
        "        h = Dense(expert_units[1], activation=None,\n",
        "                  kernel_regularizer=l2(l2_reg), name=f\"exp{i}_d2\")(h)\n",
        "        h = BatchNormalization(name=f\"exp{i}_bn2\")(h)\n",
        "        h = ReLU()(h)  # Используем слой ReLU здесь\n",
        "        h = Dropout(dropout_rate, name=f\"exp{i}_do2\")(h)\n",
        "\n",
        "        expert_outputs.append(h)\n",
        "\n",
        "    # Стек и взвешивание\n",
        "    expert_stack = Lambda(lambda t: tf.stack(t, axis=1), name=\"stack\")(expert_outputs)\n",
        "    weights_exp = Lambda(lambda t: tf.expand_dims(t, -1), name=\"expand\")(gate_weights)\n",
        "    gated = Lambda(lambda args: tf.reduce_sum(args[0] * args[1], axis=1), name=\"gated\")(\n",
        "        [expert_stack, weights_exp]\n",
        "    )\n",
        "\n",
        "    out = Dense(1, activation='sigmoid', name=\"output\")(gated)\n",
        "    return Model(inputs=x, outputs=out, name=\"GG-MoE-Adv\")\n",
        "\n",
        "\n",
        "initial_lr = 1e-3\n",
        "decay_steps = 10000\n",
        "lr_schedule = CosineDecay(initial_lr, decay_steps)\n",
        "\n",
        "# Построение и компиляция\n",
        "model = build_gg_moe(input_dim=X_train_pca.shape[1])\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=lr_schedule)\n",
        "model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Callbacks\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=50, restore_best_weights=True)\n",
        "\n",
        "# Обучение\n",
        "model.fit(X_train_pca, y_train,\n",
        "          validation_data=(X_test_pca, y_test),\n",
        "          epochs=1000, batch_size=128,\n",
        "          callbacks=[early_stop])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WE7EVqglMyj5",
        "outputId": "0e874813-7cb4-446a-d416-b76ec1df28c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 2s/step - accuracy: 0.7060 - loss: 0.6755 - val_accuracy: 0.8488 - val_loss: 0.5848\n",
            "Epoch 2/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 20ms/step - accuracy: 0.8664 - loss: 0.4383 - val_accuracy: 0.8450 - val_loss: 0.5228\n",
            "Epoch 3/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.8529 - loss: 0.4162 - val_accuracy: 0.8450 - val_loss: 0.4913\n",
            "Epoch 4/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8747 - loss: 0.3922 - val_accuracy: 0.8566 - val_loss: 0.4749\n",
            "Epoch 5/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8585 - loss: 0.4009 - val_accuracy: 0.8605 - val_loss: 0.4616\n",
            "Epoch 6/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8567 - loss: 0.3886 - val_accuracy: 0.8605 - val_loss: 0.4496\n",
            "Epoch 7/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8511 - loss: 0.4024 - val_accuracy: 0.8605 - val_loss: 0.4425\n",
            "Epoch 8/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8654 - loss: 0.3812 - val_accuracy: 0.8643 - val_loss: 0.4346\n",
            "Epoch 9/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step - accuracy: 0.8535 - loss: 0.3954 - val_accuracy: 0.8721 - val_loss: 0.4306\n",
            "Epoch 10/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8843 - loss: 0.3484 - val_accuracy: 0.8643 - val_loss: 0.4263\n",
            "Epoch 11/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 27ms/step - accuracy: 0.8711 - loss: 0.3709 - val_accuracy: 0.8721 - val_loss: 0.4243\n",
            "Epoch 12/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8548 - loss: 0.3824 - val_accuracy: 0.8682 - val_loss: 0.4242\n",
            "Epoch 13/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 29ms/step - accuracy: 0.8922 - loss: 0.3426 - val_accuracy: 0.8682 - val_loss: 0.4200\n",
            "Epoch 14/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step - accuracy: 0.8781 - loss: 0.3702 - val_accuracy: 0.8760 - val_loss: 0.4165\n",
            "Epoch 15/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8743 - loss: 0.3774 - val_accuracy: 0.8721 - val_loss: 0.4149\n",
            "Epoch 16/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8753 - loss: 0.3582 - val_accuracy: 0.8682 - val_loss: 0.4112\n",
            "Epoch 17/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8860 - loss: 0.3646 - val_accuracy: 0.8760 - val_loss: 0.4067\n",
            "Epoch 18/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8766 - loss: 0.3632 - val_accuracy: 0.8605 - val_loss: 0.4098\n",
            "Epoch 19/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8646 - loss: 0.3779 - val_accuracy: 0.8605 - val_loss: 0.4099\n",
            "Epoch 20/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8692 - loss: 0.3734 - val_accuracy: 0.8682 - val_loss: 0.4040\n",
            "Epoch 21/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8759 - loss: 0.3608 - val_accuracy: 0.8721 - val_loss: 0.4015\n",
            "Epoch 22/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8757 - loss: 0.3640 - val_accuracy: 0.8760 - val_loss: 0.3957\n",
            "Epoch 23/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8613 - loss: 0.3701 - val_accuracy: 0.8682 - val_loss: 0.3889\n",
            "Epoch 24/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8758 - loss: 0.3583 - val_accuracy: 0.8682 - val_loss: 0.3909\n",
            "Epoch 25/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8680 - loss: 0.3723 - val_accuracy: 0.8682 - val_loss: 0.3879\n",
            "Epoch 26/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8827 - loss: 0.3565 - val_accuracy: 0.8643 - val_loss: 0.3874\n",
            "Epoch 27/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8669 - loss: 0.3637 - val_accuracy: 0.8682 - val_loss: 0.3833\n",
            "Epoch 28/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8621 - loss: 0.3659 - val_accuracy: 0.8682 - val_loss: 0.3888\n",
            "Epoch 29/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8829 - loss: 0.3376 - val_accuracy: 0.8643 - val_loss: 0.3911\n",
            "Epoch 30/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8742 - loss: 0.3661 - val_accuracy: 0.8566 - val_loss: 0.3891\n",
            "Epoch 31/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8693 - loss: 0.3617 - val_accuracy: 0.8566 - val_loss: 0.3869\n",
            "Epoch 32/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8889 - loss: 0.3251 - val_accuracy: 0.8605 - val_loss: 0.3844\n",
            "Epoch 33/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8779 - loss: 0.3467 - val_accuracy: 0.8566 - val_loss: 0.3914\n",
            "Epoch 34/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8758 - loss: 0.3474 - val_accuracy: 0.8643 - val_loss: 0.3886\n",
            "Epoch 35/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8768 - loss: 0.3588 - val_accuracy: 0.8643 - val_loss: 0.3829\n",
            "Epoch 36/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8828 - loss: 0.3351 - val_accuracy: 0.8605 - val_loss: 0.3831\n",
            "Epoch 37/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8801 - loss: 0.3353 - val_accuracy: 0.8605 - val_loss: 0.3871\n",
            "Epoch 38/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8949 - loss: 0.3290 - val_accuracy: 0.8411 - val_loss: 0.3903\n",
            "Epoch 39/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8822 - loss: 0.3482 - val_accuracy: 0.8488 - val_loss: 0.3948\n",
            "Epoch 40/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8779 - loss: 0.3404 - val_accuracy: 0.8643 - val_loss: 0.3915\n",
            "Epoch 41/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 25ms/step - accuracy: 0.8825 - loss: 0.3333 - val_accuracy: 0.8605 - val_loss: 0.3763\n",
            "Epoch 42/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8865 - loss: 0.3442 - val_accuracy: 0.8605 - val_loss: 0.3708\n",
            "Epoch 43/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8816 - loss: 0.3364 - val_accuracy: 0.8760 - val_loss: 0.3722\n",
            "Epoch 44/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8833 - loss: 0.3467 - val_accuracy: 0.8566 - val_loss: 0.3813\n",
            "Epoch 45/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8827 - loss: 0.3362 - val_accuracy: 0.8682 - val_loss: 0.3968\n",
            "Epoch 46/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8734 - loss: 0.3544 - val_accuracy: 0.8760 - val_loss: 0.3940\n",
            "Epoch 47/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8761 - loss: 0.3466 - val_accuracy: 0.8643 - val_loss: 0.3852\n",
            "Epoch 48/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8819 - loss: 0.3463 - val_accuracy: 0.8682 - val_loss: 0.3746\n",
            "Epoch 49/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8720 - loss: 0.3341 - val_accuracy: 0.8605 - val_loss: 0.3725\n",
            "Epoch 50/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8799 - loss: 0.3495 - val_accuracy: 0.8605 - val_loss: 0.3719\n",
            "Epoch 51/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8754 - loss: 0.3501 - val_accuracy: 0.8643 - val_loss: 0.3666\n",
            "Epoch 52/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8919 - loss: 0.3284 - val_accuracy: 0.8605 - val_loss: 0.3757\n",
            "Epoch 53/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9018 - loss: 0.3115 - val_accuracy: 0.8566 - val_loss: 0.3874\n",
            "Epoch 54/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8882 - loss: 0.3286 - val_accuracy: 0.8566 - val_loss: 0.3885\n",
            "Epoch 55/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8852 - loss: 0.3210 - val_accuracy: 0.8527 - val_loss: 0.3869\n",
            "Epoch 56/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8752 - loss: 0.3380 - val_accuracy: 0.8605 - val_loss: 0.3880\n",
            "Epoch 57/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8814 - loss: 0.3259 - val_accuracy: 0.8566 - val_loss: 0.3860\n",
            "Epoch 58/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8957 - loss: 0.3110 - val_accuracy: 0.8643 - val_loss: 0.3768\n",
            "Epoch 59/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8928 - loss: 0.3166 - val_accuracy: 0.8605 - val_loss: 0.3717\n",
            "Epoch 60/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8970 - loss: 0.2929 - val_accuracy: 0.8605 - val_loss: 0.3869\n",
            "Epoch 61/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8870 - loss: 0.3155 - val_accuracy: 0.8566 - val_loss: 0.3879\n",
            "Epoch 62/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8821 - loss: 0.3247 - val_accuracy: 0.8527 - val_loss: 0.3815\n",
            "Epoch 63/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8815 - loss: 0.3247 - val_accuracy: 0.8605 - val_loss: 0.3743\n",
            "Epoch 64/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8714 - loss: 0.3419 - val_accuracy: 0.8488 - val_loss: 0.3722\n",
            "Epoch 65/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 23ms/step - accuracy: 0.8954 - loss: 0.3256 - val_accuracy: 0.8450 - val_loss: 0.3993\n",
            "Epoch 66/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step - accuracy: 0.8875 - loss: 0.3295 - val_accuracy: 0.8527 - val_loss: 0.3758\n",
            "Epoch 67/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.8815 - loss: 0.3378 - val_accuracy: 0.8605 - val_loss: 0.3679\n",
            "Epoch 68/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8861 - loss: 0.2993 - val_accuracy: 0.8682 - val_loss: 0.3669\n",
            "Epoch 69/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8841 - loss: 0.3091 - val_accuracy: 0.8605 - val_loss: 0.3706\n",
            "Epoch 70/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8946 - loss: 0.3053 - val_accuracy: 0.8605 - val_loss: 0.3770\n",
            "Epoch 71/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9122 - loss: 0.2939 - val_accuracy: 0.8605 - val_loss: 0.3710\n",
            "Epoch 72/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9077 - loss: 0.3000 - val_accuracy: 0.8682 - val_loss: 0.3735\n",
            "Epoch 73/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8904 - loss: 0.3017 - val_accuracy: 0.8566 - val_loss: 0.3836\n",
            "Epoch 74/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8906 - loss: 0.3119 - val_accuracy: 0.8682 - val_loss: 0.3678\n",
            "Epoch 75/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8872 - loss: 0.3145 - val_accuracy: 0.8643 - val_loss: 0.3738\n",
            "Epoch 76/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8878 - loss: 0.3250 - val_accuracy: 0.8682 - val_loss: 0.3962\n",
            "Epoch 77/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8878 - loss: 0.3126 - val_accuracy: 0.8682 - val_loss: 0.3885\n",
            "Epoch 78/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8954 - loss: 0.3012 - val_accuracy: 0.8682 - val_loss: 0.3785\n",
            "Epoch 79/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8770 - loss: 0.3379 - val_accuracy: 0.8605 - val_loss: 0.3704\n",
            "Epoch 80/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8808 - loss: 0.3185 - val_accuracy: 0.8605 - val_loss: 0.3734\n",
            "Epoch 81/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8825 - loss: 0.3189 - val_accuracy: 0.8605 - val_loss: 0.3750\n",
            "Epoch 82/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8899 - loss: 0.3178 - val_accuracy: 0.8605 - val_loss: 0.3748\n",
            "Epoch 83/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8956 - loss: 0.3033 - val_accuracy: 0.8566 - val_loss: 0.3693\n",
            "Epoch 84/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9007 - loss: 0.3119 - val_accuracy: 0.8566 - val_loss: 0.3836\n",
            "Epoch 85/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8987 - loss: 0.3112 - val_accuracy: 0.8527 - val_loss: 0.3904\n",
            "Epoch 86/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8873 - loss: 0.3183 - val_accuracy: 0.8605 - val_loss: 0.3929\n",
            "Epoch 87/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8888 - loss: 0.3163 - val_accuracy: 0.8605 - val_loss: 0.3865\n",
            "Epoch 88/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9009 - loss: 0.2960 - val_accuracy: 0.8527 - val_loss: 0.3828\n",
            "Epoch 89/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8781 - loss: 0.3209 - val_accuracy: 0.8527 - val_loss: 0.3813\n",
            "Epoch 90/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8953 - loss: 0.2941 - val_accuracy: 0.8566 - val_loss: 0.3802\n",
            "Epoch 91/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9031 - loss: 0.2998 - val_accuracy: 0.8527 - val_loss: 0.3829\n",
            "Epoch 92/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8946 - loss: 0.3032 - val_accuracy: 0.8527 - val_loss: 0.3860\n",
            "Epoch 93/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8898 - loss: 0.2923 - val_accuracy: 0.8527 - val_loss: 0.3811\n",
            "Epoch 94/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9023 - loss: 0.3040 - val_accuracy: 0.8488 - val_loss: 0.3803\n",
            "Epoch 95/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8994 - loss: 0.2979 - val_accuracy: 0.8566 - val_loss: 0.3885\n",
            "Epoch 96/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8898 - loss: 0.3158 - val_accuracy: 0.8566 - val_loss: 0.3972\n",
            "Epoch 97/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8895 - loss: 0.3210 - val_accuracy: 0.8566 - val_loss: 0.3914\n",
            "Epoch 98/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8851 - loss: 0.3177 - val_accuracy: 0.8605 - val_loss: 0.3911\n",
            "Epoch 99/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8809 - loss: 0.3171 - val_accuracy: 0.8605 - val_loss: 0.3914\n",
            "Epoch 100/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8953 - loss: 0.3081 - val_accuracy: 0.8527 - val_loss: 0.3899\n",
            "Epoch 101/1000\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9014 - loss: 0.2856 - val_accuracy: 0.8527 - val_loss: 0.3888\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79550f79a010>"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = model.predict(X_test_pca)\n",
        "print('Accuracy:', accuracy_score(y_test, (y_pred >= 0.5).astype(int)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r4u1gMRlLD2T",
        "outputId": "6ec0d799-b33c-4135-900b-9895df1e5c59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 108ms/step\n",
            "Accuracy: 0.8798449612403101\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ! pip install category-encoders"
      ],
      "metadata": {
        "id": "fSZ4Wy_VQAYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Layer\n",
        "\n",
        "class StackExperts(Layer):\n",
        "    def call(self, inputs):\n",
        "        # inputs: list of tensors [exp0_out, exp1_out, …]\n",
        "        return tf.stack(inputs, axis=1)\n",
        "\n",
        "class ExpandDims(Layer):\n",
        "    def call(self, inputs):\n",
        "        # inputs: tensor of shape (batch, n_experts)\n",
        "        return tf.expand_dims(inputs, axis=-1)\n",
        "\n",
        "class WeightedSum(Layer):\n",
        "    def call(self, inputs):\n",
        "        # inputs: [expert_stack, gate_weights_expanded]\n",
        "        expert_stack, gate_w_exp = inputs\n",
        "        # both have compatible dtypes (float32)\n",
        "        return tf.reduce_sum(expert_stack * gate_w_exp, axis=1)"
      ],
      "metadata": {
        "id": "R4thPr5ORzVk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.ensemble import IsolationForest\n",
        "from imblearn.over_sampling import SMOTE\n",
        "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
        "from category_encoders import TargetEncoder\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "import lightgbm as lgb\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Dropout, Lambda, BatchNormalization, ReLU\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "\n",
        "# === 1. Загрузка и очистка ===\n",
        "dt = df_train\n",
        "df_test = df_test\n",
        "\n",
        "# 1.1. Удаляем выбросы с помощью IsolationForest\n",
        "iso = IsolationForest(contamination=0.01, random_state=42)\n",
        "mask = iso.fit_predict(dt.drop(['target'], axis=1)) == 1\n",
        "dt = dt.loc[mask].reset_index(drop=True)\n",
        "\n",
        "# === 2. Балансировка классов (SMOTE) ===\n",
        "X = dt.drop('target', axis=1)\n",
        "y = dt['target']\n",
        "sm = SMOTE(random_state=42)\n",
        "X_res, y_res = sm.fit_resample(X, y)\n",
        "\n",
        "# === 3. Feature Engineering ===\n",
        "# 3.1 Target Encoding для категорий\n",
        "cat_cols = X_res.select_dtypes(['object','category']).columns.tolist()\n",
        "te = TargetEncoder(cols=cat_cols)\n",
        "X_res = te.fit_transform(X_res, y_res)\n",
        "df_test_enc = te.transform(df_test)\n",
        "\n",
        "# 3.2 Полиномиальные признаки\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "X_poly = poly.fit_transform(X_res)\n",
        "X_test_poly = poly.transform(df_test_enc)\n",
        "\n",
        "# 3.3 Масштабирование\n",
        "scaler = StandardScaler()\n",
        "X_poly = scaler.fit_transform(X_poly)\n",
        "X_test_poly = scaler.transform(X_test_poly)\n",
        "\n",
        "# === 4. Первичная модель LightGBM ===\n",
        "lgb_params = {\n",
        "    'objective':'binary',\n",
        "    'learning_rate':0.05,\n",
        "    'num_leaves':31,\n",
        "    'metric':'binary_logloss',\n",
        "    'verbose': -1,\n",
        "}\n",
        "dtrain = lgb.Dataset(X_poly, label=y_res)\n",
        "lgb_model = lgb.train(lgb_params, dtrain, num_boost_round=500)\n",
        "\n",
        "# 4.1 Псевдолейблинг: выбираем уверенные предсказания\n",
        "probs_test = lgb_model.predict(X_test_poly)\n",
        "mask_high = (probs_test > 0.9) | (probs_test < 0.1)\n",
        "pseudo_X = X_test_poly[mask_high]\n",
        "pseudo_y = (probs_test[mask_high] > 0.5).astype(int)\n",
        "\n",
        "# Объединяем\n",
        "X_final = np.vstack([X_poly, pseudo_X])\n",
        "y_final = np.concatenate([y_res, pseudo_y])\n",
        "\n",
        "# === 5. Обучение GG-MoE на объединённых данных ===\n",
        "def build_gg_moe(input_dim,\n",
        "                 n_experts=8,\n",
        "                 expert_units=[128, 64],\n",
        "                 gate_units=32,\n",
        "                 dropout_rate=0.2,\n",
        "                 l2_reg=1e-4):\n",
        "    x = Input(shape=(input_dim,), name=\"input\")\n",
        "\n",
        "    # 1) Gating network\n",
        "    g = Dense(gate_units, kernel_regularizer=l2(l2_reg), name=\"gate_dense\")(x)\n",
        "    g = BatchNormalization(name=\"gate_bn\")(g)\n",
        "    g = ReLU(name=\"gate_relu\")(g)\n",
        "    logits = Dense(n_experts, kernel_regularizer=l2(l2_reg), name=\"gate_logits\")(g)\n",
        "    gate_w = tf.keras.layers.Softmax(name=\"gate_softmax\")(logits)  # встроенный softmax слой\n",
        "\n",
        "    # 2) Эксперты\n",
        "    experts = []\n",
        "    for i in range(n_experts):\n",
        "        h = Dense(expert_units[0], kernel_regularizer=l2(l2_reg), name=f\"exp{i}_d1\")(x)\n",
        "        h = BatchNormalization(name=f\"exp{i}_bn1\")(h)\n",
        "        h = ReLU(name=f\"exp{i}_relu1\")(h)\n",
        "        h = Dropout(dropout_rate, name=f\"exp{i}_do1\")(h)\n",
        "\n",
        "        h = Dense(expert_units[1], kernel_regularizer=l2(l2_reg), name=f\"exp{i}_d2\")(h)\n",
        "        h = BatchNormalization(name=f\"exp{i}_bn2\")(h)\n",
        "        h = ReLU(name=f\"exp{i}_relu2\")(h)\n",
        "        h = Dropout(dropout_rate, name=f\"exp{i}_do2\")(h)\n",
        "\n",
        "        experts.append(h)\n",
        "\n",
        "    # 3) Стек и взвешивание\n",
        "    stack = StackExperts(name=\"stack_experts\")(experts)              # (batch, n_experts, units)\n",
        "    gate_w_exp = ExpandDims(name=\"expand_dims\")(gate_w)            # (batch, n_experts, 1)\n",
        "    gated = WeightedSum(name=\"weighted_sum\")([stack, gate_w_exp])  # (batch, units)\n",
        "\n",
        "    # 4) Финальный выход\n",
        "    out = Dense(1, activation='sigmoid', name=\"output\")(gated)\n",
        "\n",
        "    return Model(inputs=x, outputs=out, name=\"GG-MoE-Adv-Custom\")\n"
      ],
      "metadata": {
        "id": "xMPK3vLYQqcU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Преобразуем данные в нужные типы\n",
        "X_final = X_final.astype('float32')\n",
        "y_final = y_final.astype('int32')\n",
        "\n",
        "# Построение модели\n",
        "input_dim = X_final.shape[1]\n",
        "moe = build_gg_moe(input_dim)\n",
        "\n",
        "# Компиляция с CosineDecay\n",
        "from tensorflow.keras.optimizers.schedules import CosineDecay\n",
        "lr_schedule = CosineDecay(1e-3, decay_steps=10000)\n",
        "moe.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "    loss='binary_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Обучение\n",
        "moe.fit(\n",
        "    X_final,\n",
        "    y_final,\n",
        "    epochs=100,\n",
        "    batch_size=128,\n",
        "    validation_split=0.1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "# === 6. Стэкинг ===\n",
        "# 6.1 OOF-предсказания для LightGBM и MoE\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "oof_lgb = np.zeros(len(X_poly))\n",
        "oof_moe = np.zeros(len(X_poly))\n",
        "for train_idx, val_idx in kf.split(X_poly, y_res):\n",
        "    # LGB\n",
        "    dl = lgb.Dataset(X_poly[train_idx], label=y_res[train_idx])\n",
        "    model_fold = lgb.train(lgb_params, dl, num_boost_round=300)\n",
        "    oof_lgb[val_idx] = model_fold.predict(X_poly[val_idx])\n",
        "    # MoE\n",
        "    moe_fold = build_gg_moe(input_dim)\n",
        "    moe_fold.compile(tf.keras.optimizers.Adam(1e-3), 'binary_crossentropy')\n",
        "    moe_fold.fit(X_final[train_idx], y_final[train_idx], epochs=50, batch_size=128, verbose=0)\n",
        "    oof_moe[val_idx] = moe_fold.predict(X_poly[val_idx]).ravel()\n",
        "\n",
        "# 6.2 Метамодель\n",
        "stack_X = np.vstack([oof_lgb, oof_moe]).T\n",
        "stacker = LogisticRegression()\n",
        "stacker.fit(stack_X, y_res)\n",
        "\n",
        "# === 7. Финальные предсказания на тесте ===\n",
        "test_lgb = lgb_model.predict(X_test_poly)\n",
        "test_moe = moe.predict(X_test_poly).ravel()\n",
        "stack_test = np.vstack([test_lgb, test_moe]).T\n",
        "final_preds = stacker.predict(stack_test)\n",
        "\n",
        "# Сохраняем ответы\n",
        "pd.DataFrame({'target': final_preds}).to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJS7JqyCPz1n",
        "outputId": "51d5b867-43bc-47e1-a38e-36c246950c62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 1s/step - accuracy: 0.7625 - loss: 0.6638 - val_accuracy: 0.9624 - val_loss: 0.3292\n",
            "Epoch 2/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 18ms/step - accuracy: 0.8609 - loss: 0.4893 - val_accuracy: 0.9624 - val_loss: 0.3021\n",
            "Epoch 3/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8768 - loss: 0.4682 - val_accuracy: 0.9624 - val_loss: 0.2901\n",
            "Epoch 4/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8879 - loss: 0.4499 - val_accuracy: 0.9731 - val_loss: 0.2795\n",
            "Epoch 5/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8855 - loss: 0.4374 - val_accuracy: 0.9677 - val_loss: 0.2742\n",
            "Epoch 6/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8774 - loss: 0.4376 - val_accuracy: 0.9677 - val_loss: 0.2850\n",
            "Epoch 7/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8869 - loss: 0.4208 - val_accuracy: 0.9731 - val_loss: 0.2752\n",
            "Epoch 8/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8824 - loss: 0.4442 - val_accuracy: 0.9731 - val_loss: 0.2746\n",
            "Epoch 9/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8791 - loss: 0.4260 - val_accuracy: 0.9570 - val_loss: 0.2767\n",
            "Epoch 10/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8939 - loss: 0.4115 - val_accuracy: 0.9785 - val_loss: 0.2612\n",
            "Epoch 11/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8893 - loss: 0.4167 - val_accuracy: 0.9731 - val_loss: 0.2626\n",
            "Epoch 12/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8845 - loss: 0.4274 - val_accuracy: 0.9839 - val_loss: 0.2562\n",
            "Epoch 13/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8831 - loss: 0.4115 - val_accuracy: 0.9731 - val_loss: 0.2649\n",
            "Epoch 14/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9024 - loss: 0.3939 - val_accuracy: 0.9839 - val_loss: 0.2449\n",
            "Epoch 15/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9003 - loss: 0.3888 - val_accuracy: 0.9785 - val_loss: 0.2598\n",
            "Epoch 16/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8914 - loss: 0.4098 - val_accuracy: 0.9839 - val_loss: 0.2467\n",
            "Epoch 17/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8912 - loss: 0.3833 - val_accuracy: 0.9892 - val_loss: 0.2415\n",
            "Epoch 18/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9006 - loss: 0.3922 - val_accuracy: 0.9785 - val_loss: 0.2414\n",
            "Epoch 19/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8979 - loss: 0.3771 - val_accuracy: 0.9731 - val_loss: 0.2424\n",
            "Epoch 20/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8905 - loss: 0.3946 - val_accuracy: 0.9785 - val_loss: 0.2314\n",
            "Epoch 21/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8925 - loss: 0.3796 - val_accuracy: 0.9731 - val_loss: 0.2349\n",
            "Epoch 22/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8885 - loss: 0.3831 - val_accuracy: 0.9731 - val_loss: 0.2321\n",
            "Epoch 23/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8883 - loss: 0.3771 - val_accuracy: 0.9839 - val_loss: 0.2275\n",
            "Epoch 24/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8959 - loss: 0.3787 - val_accuracy: 0.9892 - val_loss: 0.2217\n",
            "Epoch 25/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8962 - loss: 0.3717 - val_accuracy: 0.9892 - val_loss: 0.2234\n",
            "Epoch 26/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8850 - loss: 0.3837 - val_accuracy: 0.9892 - val_loss: 0.2203\n",
            "Epoch 27/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8902 - loss: 0.3721 - val_accuracy: 0.9785 - val_loss: 0.2181\n",
            "Epoch 28/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8702 - loss: 0.4073 - val_accuracy: 0.9839 - val_loss: 0.2242\n",
            "Epoch 29/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8962 - loss: 0.3710 - val_accuracy: 0.9946 - val_loss: 0.2009\n",
            "Epoch 30/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8933 - loss: 0.3654 - val_accuracy: 0.9892 - val_loss: 0.2082\n",
            "Epoch 31/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8982 - loss: 0.3642 - val_accuracy: 0.9892 - val_loss: 0.2123\n",
            "Epoch 32/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8978 - loss: 0.3669 - val_accuracy: 0.9839 - val_loss: 0.2222\n",
            "Epoch 33/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9121 - loss: 0.3421 - val_accuracy: 0.9892 - val_loss: 0.1971\n",
            "Epoch 34/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8951 - loss: 0.3558 - val_accuracy: 0.9946 - val_loss: 0.2099\n",
            "Epoch 35/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9019 - loss: 0.3507 - val_accuracy: 0.9892 - val_loss: 0.2060\n",
            "Epoch 36/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9123 - loss: 0.3439 - val_accuracy: 0.9892 - val_loss: 0.1989\n",
            "Epoch 37/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9099 - loss: 0.3362 - val_accuracy: 0.9946 - val_loss: 0.1932\n",
            "Epoch 38/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8950 - loss: 0.3583 - val_accuracy: 0.9946 - val_loss: 0.1961\n",
            "Epoch 39/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9033 - loss: 0.3490 - val_accuracy: 0.9946 - val_loss: 0.1918\n",
            "Epoch 40/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9042 - loss: 0.3569 - val_accuracy: 0.9946 - val_loss: 0.1968\n",
            "Epoch 41/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9074 - loss: 0.3378 - val_accuracy: 0.9892 - val_loss: 0.1915\n",
            "Epoch 42/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9052 - loss: 0.3445 - val_accuracy: 0.9839 - val_loss: 0.1916\n",
            "Epoch 43/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9027 - loss: 0.3364 - val_accuracy: 0.9946 - val_loss: 0.1928\n",
            "Epoch 44/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9130 - loss: 0.3215 - val_accuracy: 0.9839 - val_loss: 0.1839\n",
            "Epoch 45/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.8920 - loss: 0.3453 - val_accuracy: 0.9946 - val_loss: 0.1811\n",
            "Epoch 46/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9121 - loss: 0.3194 - val_accuracy: 0.9946 - val_loss: 0.1811\n",
            "Epoch 47/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9056 - loss: 0.3331 - val_accuracy: 0.9892 - val_loss: 0.1767\n",
            "Epoch 48/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8850 - loss: 0.3563 - val_accuracy: 0.9892 - val_loss: 0.1855\n",
            "Epoch 49/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9094 - loss: 0.3184 - val_accuracy: 0.9785 - val_loss: 0.1908\n",
            "Epoch 50/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9063 - loss: 0.3297 - val_accuracy: 0.9839 - val_loss: 0.1793\n",
            "Epoch 51/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8972 - loss: 0.3302 - val_accuracy: 0.9839 - val_loss: 0.1806\n",
            "Epoch 52/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9147 - loss: 0.3168 - val_accuracy: 0.9892 - val_loss: 0.1830\n",
            "Epoch 53/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8837 - loss: 0.3517 - val_accuracy: 0.9785 - val_loss: 0.1828\n",
            "Epoch 54/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9026 - loss: 0.3362 - val_accuracy: 0.9839 - val_loss: 0.1594\n",
            "Epoch 55/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9129 - loss: 0.3185 - val_accuracy: 0.9839 - val_loss: 0.1731\n",
            "Epoch 56/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9050 - loss: 0.3339 - val_accuracy: 0.9839 - val_loss: 0.1746\n",
            "Epoch 57/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9072 - loss: 0.3275 - val_accuracy: 0.9892 - val_loss: 0.1661\n",
            "Epoch 58/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8993 - loss: 0.3304 - val_accuracy: 0.9892 - val_loss: 0.1806\n",
            "Epoch 59/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9024 - loss: 0.3201 - val_accuracy: 0.9839 - val_loss: 0.1854\n",
            "Epoch 60/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8968 - loss: 0.3336 - val_accuracy: 0.9892 - val_loss: 0.1741\n",
            "Epoch 61/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9199 - loss: 0.2974 - val_accuracy: 0.9839 - val_loss: 0.1738\n",
            "Epoch 62/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9040 - loss: 0.3269 - val_accuracy: 0.9839 - val_loss: 0.1797\n",
            "Epoch 63/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9231 - loss: 0.3031 - val_accuracy: 0.9839 - val_loss: 0.1804\n",
            "Epoch 64/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9109 - loss: 0.3076 - val_accuracy: 0.9839 - val_loss: 0.1930\n",
            "Epoch 65/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9120 - loss: 0.2985 - val_accuracy: 0.9731 - val_loss: 0.1780\n",
            "Epoch 66/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9139 - loss: 0.3176 - val_accuracy: 0.9839 - val_loss: 0.1731\n",
            "Epoch 67/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9129 - loss: 0.3165 - val_accuracy: 0.9892 - val_loss: 0.1589\n",
            "Epoch 68/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9137 - loss: 0.3002 - val_accuracy: 0.9946 - val_loss: 0.1627\n",
            "Epoch 69/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9137 - loss: 0.2957 - val_accuracy: 0.9892 - val_loss: 0.1672\n",
            "Epoch 70/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8998 - loss: 0.3171 - val_accuracy: 0.9785 - val_loss: 0.1847\n",
            "Epoch 71/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9085 - loss: 0.3255 - val_accuracy: 0.9892 - val_loss: 0.1741\n",
            "Epoch 72/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9065 - loss: 0.2992 - val_accuracy: 0.9839 - val_loss: 0.1699\n",
            "Epoch 73/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9139 - loss: 0.2898 - val_accuracy: 0.9839 - val_loss: 0.1732\n",
            "Epoch 74/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9091 - loss: 0.3183 - val_accuracy: 0.9892 - val_loss: 0.1774\n",
            "Epoch 75/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9225 - loss: 0.2825 - val_accuracy: 0.9785 - val_loss: 0.1635\n",
            "Epoch 76/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9052 - loss: 0.3006 - val_accuracy: 0.9839 - val_loss: 0.1685\n",
            "Epoch 77/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9172 - loss: 0.2804 - val_accuracy: 0.9839 - val_loss: 0.1619\n",
            "Epoch 78/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9171 - loss: 0.2933 - val_accuracy: 0.9839 - val_loss: 0.1731\n",
            "Epoch 79/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9104 - loss: 0.2856 - val_accuracy: 0.9892 - val_loss: 0.1754\n",
            "Epoch 80/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9065 - loss: 0.2936 - val_accuracy: 0.9892 - val_loss: 0.1738\n",
            "Epoch 81/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9238 - loss: 0.2866 - val_accuracy: 0.9892 - val_loss: 0.1653\n",
            "Epoch 82/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9151 - loss: 0.2848 - val_accuracy: 0.9892 - val_loss: 0.1537\n",
            "Epoch 83/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9128 - loss: 0.2969 - val_accuracy: 0.9839 - val_loss: 0.1576\n",
            "Epoch 84/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9088 - loss: 0.2918 - val_accuracy: 0.9892 - val_loss: 0.1605\n",
            "Epoch 85/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9132 - loss: 0.2998 - val_accuracy: 0.9839 - val_loss: 0.1648\n",
            "Epoch 86/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9086 - loss: 0.3107 - val_accuracy: 0.9892 - val_loss: 0.1506\n",
            "Epoch 87/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9127 - loss: 0.2936 - val_accuracy: 0.9785 - val_loss: 0.1706\n",
            "Epoch 88/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9064 - loss: 0.3123 - val_accuracy: 0.9946 - val_loss: 0.1635\n",
            "Epoch 89/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8865 - loss: 0.3374 - val_accuracy: 0.9839 - val_loss: 0.1651\n",
            "Epoch 90/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9187 - loss: 0.2895 - val_accuracy: 0.9839 - val_loss: 0.1691\n",
            "Epoch 91/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9066 - loss: 0.3090 - val_accuracy: 0.9839 - val_loss: 0.1632\n",
            "Epoch 92/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9037 - loss: 0.3124 - val_accuracy: 0.9785 - val_loss: 0.1653\n",
            "Epoch 93/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8973 - loss: 0.3137 - val_accuracy: 0.9839 - val_loss: 0.1483\n",
            "Epoch 94/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9185 - loss: 0.2896 - val_accuracy: 0.9892 - val_loss: 0.1459\n",
            "Epoch 95/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.8996 - loss: 0.3145 - val_accuracy: 0.9892 - val_loss: 0.1496\n",
            "Epoch 96/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9195 - loss: 0.2742 - val_accuracy: 0.9892 - val_loss: 0.1454\n",
            "Epoch 97/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9182 - loss: 0.2757 - val_accuracy: 0.9892 - val_loss: 0.1480\n",
            "Epoch 98/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9026 - loss: 0.3077 - val_accuracy: 0.9839 - val_loss: 0.1546\n",
            "Epoch 99/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9103 - loss: 0.2875 - val_accuracy: 0.9892 - val_loss: 0.1516\n",
            "Epoch 100/100\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9202 - loss: 0.2730 - val_accuracy: 0.9892 - val_loss: 0.1600\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 196ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 114ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 116ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 197ms/step\n",
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 119ms/step\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 86ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ans = pd.read_csv('submission.csv')"
      ],
      "metadata": {
        "id": "STy2dPtnQT5F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame({'target': final_preds}).to_csv('preds.csv', index=False, header=False)"
      ],
      "metadata": {
        "id": "mP__y7-KU6ry"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Качество на тестовой выборке: 0.9162790697674419\n",
        "\n",
        "test_model_accuracy (__main__.TestAccuracy.test_model_accuracy) ... ok\n",
        "\n"
      ],
      "metadata": {
        "id": "Rz1Nz546VwvX"
      }
    }
  ]
}